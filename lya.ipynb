{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1beb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Riley Owens (GitHub: mrileyowens)\n",
    "\n",
    "# This file measures values and errors of \n",
    "# various Lyα profile parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92eb6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erf\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "\n",
    "import sigfig\n",
    "from sigfig import round as sf_round\n",
    "#from to_precision import std_notation\n",
    "import decimal\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf4643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure():\n",
    "\n",
    "    def extract_data(file):\n",
    "\n",
    "        '''\n",
    "        Extract spectrum from the .txt file\n",
    "\n",
    "        Parameters:\n",
    "            file : str\n",
    "                Name of the file\n",
    "\n",
    "        Returns:\n",
    "            w : numpy.ndarray\n",
    "                Observed wavelength bins\n",
    "            f : numpy.ndarray\n",
    "                Observed flux densities\n",
    "            n : numpy.ndarray\n",
    "                Observed Gaussian standard deviation of observed flux densities\n",
    "        '''\n",
    "\n",
    "        # Retrieve the data columns\n",
    "        w, f, n = np.loadtxt(file, delimiter='\\t', comments=('#', 'w'), usecols=(0,1,2), unpack=True)\n",
    "    \n",
    "        # If the file is not the stacked leaker spectrum. This step is necessary because \n",
    "        if 'leaker' not in file:\n",
    "\n",
    "            # Remove bins of extreme outliers\n",
    "            w = w[f < 1e-20]\n",
    "            n = n[f < 1e-20]\n",
    "            f = f[f < 1e-20]\n",
    "\n",
    "            # Convert from units of erg/s/cm^2/Hz to erg/s/cm^2/Å\n",
    "            f = f * 2.998e18 / np.square(w)\n",
    "            n = n * 2.998e18 / np.square(w)\n",
    "\n",
    "        return w, f, n    \n",
    "\n",
    "    def compute_fwhm_and_peak(model, parameters, R, R_error):\n",
    "\n",
    "        '''\n",
    "        Returns:\n",
    "            fwhm : numpy.float64\n",
    "            loc : numpy.float64\n",
    "        '''\n",
    "        def lin_interp(x, y, i):\n",
    "            return x[i] + (x[i+1] - x[i]) * y[i] / (y[i+1] - y[i])\n",
    "\n",
    "        v = np.arange(-500,500,0.1)\n",
    "\n",
    "        #peak = model(v, amp, cen, width, skew)    \n",
    "\n",
    "        fits = []\n",
    "\n",
    "        for i, fit_params in enumerate(parameters):\n",
    "\n",
    "            fit = model(v, *fit_params)\n",
    "\n",
    "            fits.append([*fit])\n",
    "\n",
    "        fits_max_indices = np.argmax(fits, axis=1)\n",
    "\n",
    "        locs = v[fits_max_indices]#np.argmax(fits, axis=1)]\n",
    "\n",
    "        #loc = v[np.argmax(peak)]\n",
    "\n",
    "        #half = np.amax(fits) / 2.0\n",
    "        #signs = np.sign(np.add(fits, -half))\n",
    "        #zero_crossings = (signs[0:-2] != signs[1:-1])\n",
    "        #zero_crossings_i = np.where(zero_crossings)[0]\n",
    "\n",
    "        fits_halved = fits - np.amax(fits, axis=1, keepdims=True) / 2\n",
    "\n",
    "        #halfs = np.amax(fits) / 2\n",
    "        #signs = np.sign(fits - halfs)\n",
    "        crossings = np.diff(np.sign(fits_halved), axis=1) != 0\n",
    "        #zero_crossings = np.where((signs[:, :-1] != signs[:, 1:]))[0]\n",
    "\n",
    "        indices = np.array(np.where(crossings))\n",
    "\n",
    "        #indices = np.array(indices).T #np.array([indices[::2], indices[1::2]], dtype=int).T\n",
    "        #indices = np.array([np.array(indices[::2]).T, np.array(indices[1::2]).T])\n",
    "        #indices = np.array([indices[::2], indices[1::2]])\n",
    "        indices = indices.T\n",
    "\n",
    "        indices_new = []    \n",
    "\n",
    "        for i in range(1000):\n",
    "\n",
    "            fit_crossings = np.array([idx[1] for idx in indices if idx[0] == i])\n",
    "\n",
    "            min_idx = np.amax(fit_crossings[fit_crossings < fits_max_indices[i]])\n",
    "            max_idx = np.amin(fit_crossings[fit_crossings > fits_max_indices[i]])\n",
    "\n",
    "            indices_new.append([min_idx, max_idx])\n",
    "\n",
    "        fwhms = []\n",
    "\n",
    "        for i, index_pair in enumerate(indices_new):\n",
    "\n",
    "            #idx_1, idx_2 = indices[2 * i], indices[2 * i + 1]\n",
    "\n",
    "            #if abs(idx_1[1] - idx_2[1]) > 10:\n",
    "\n",
    "            #fwhm = abs(lin_interp(v, fits_halved[idx_1[0]], idx_1[1]) - lin_interp(v, fits_halved[idx_2[0]], idx_2[1]))\n",
    "\n",
    "            #fwhms.append(fwhm)\n",
    "            \n",
    "            #else:\n",
    "\n",
    "            #pass\n",
    "\n",
    "            fwhm = abs(lin_interp(v, fits_halved[i], index_pair[0]) - lin_interp(v, fits_halved[i], index_pair[1]))\n",
    "\n",
    "            fwhms.append(fwhm)\n",
    "\n",
    "        #fwhms = abs(lin_interp(v, fits, zero_crossings_i[0], half) - lin_interp(v, fits, zero_crossings_i[1], half))\n",
    "\n",
    "        res = np.random.normal(R, R_error, len(parameters))\n",
    "\n",
    "        fwhms = np.sqrt((np.array(fwhms))**2 - (res)**2)\n",
    "\n",
    "        return fwhms, locs\n",
    "\n",
    "    def two_peaks(x, amp_r, cen_r, width_r, skew_r, amp_c, cen_c, width_c, cntm):\n",
    "\n",
    "        return amp_r * np.exp(-((x - cen_r) / width_r)**2 / 2) * (1 + erf(skew_r * ((x - cen_r) / width_r) / np.sqrt(2))) \\\n",
    "            + amp_c * np.exp(-((x - cen_c) / width_c)**2 / 2) \\\n",
    "            + cntm\n",
    "\n",
    "    def three_peaks(x, amp_b, cen_b, width_b, skew_b, amp_r, cen_r, width_r, skew_r, amp_c, cen_c, width_c, cntm):\n",
    "\n",
    "        return amp_b * np.exp(-((x - cen_b) / width_b)**2 / 2) * (1 + erf(skew_b * ((x - cen_b) / width_b) / np.sqrt(2)))  \\\n",
    "            + amp_r * np.exp(-((x - cen_r) / width_r)**2 / 2) * (1 + erf(skew_r * ((x - cen_r) / width_r) / np.sqrt(2))) \\\n",
    "            + amp_c * np.exp(-((x - cen_c) / width_c)**2 / 2) \\\n",
    "            + cntm\n",
    "\n",
    "    # Establish directories\n",
    "    home = os.getcwd()\n",
    "    data = f'{home}/data'\n",
    "    results = f'{home}/results'\n",
    "\n",
    "    '''\n",
    "    files = np.array(['rest_sba-nonleaker-no_m3_MWdr.txt','rest_sba-leaker-no_m0_MWdr.txt',\n",
    "                      'psz-arcslit-h3-comb1_MWdr.txt', 'psz-arcslit-h1-comb1_MWdr.txt',\n",
    "                      'sunburst_M-6-comb1_MWdr.txt', 'psz-arcslit-h4-comb1_MWdr.txt',\n",
    "                      'planckarc_pos1-comb1_MWdr.txt', 'psz-arcslit-h6-comb1_MWdr.txt',\n",
    "                      'psz-arcslit-h9-comb1_MWdr.txt', 'psz-arcslit-f-comb1_MWdr.txt',\n",
    "                      'psz-arcslit-h2-comb1_MWdr.txt'], dtype=object)\n",
    "    names = np.array(['NL', 'L', 'M5', 'M4', 'M6', 'M3', 'M0', 'M2', 'M7', 'M8', 'M9'], dtype=str)\n",
    "    '''\n",
    "\n",
    "    slits = {\n",
    "        'NL' : ['rest_sba-nonleaker-no_m3_MWdr.txt', 0, 1, [60,140]],\n",
    "        'L' : ['rest_sba-leaker-no_m0_MWdr.txt', 0, 1, [20,130]],\n",
    "        'M5' : ['psz-arcslit-m5-comb1_MWdr.txt', 2.37086, 51, [0,100]],\n",
    "        'M4' : ['psz-arcslit-m4-comb1_MWdr.txt', 2.37073, 14.6, [0,85]],\n",
    "        'M6' : ['psz-arcslit-m6-comb1_MWdr.txt', 2.37021, 147, [10,130]],\n",
    "        'M3' : ['psz-arcslit-m3-comb1_MWdr.txt', 2.37025, 36, [35,120]],\n",
    "        'M0' : ['psz-arcslit-m0-comb1_MWdr.txt', 2.37014, 10, [10,130]],\n",
    "        'M2' : ['psz-arcslit-m2-comb1_MWdr.txt', 2.37017, 32, [45,125]],\n",
    "        'M7' : ['psz-arcslit-m7-comb1_MWdr.txt', 2.37044, 35, [15,100]],\n",
    "        'M8' : ['psz-arcslit-m8-comb1_MWdr.txt', 2.37024, 29, [25,125]],\n",
    "        'M9' : ['psz-arcslit-m9-comb1_MWdr.txt', 2.37030, 31, [15,125]]\n",
    "    }\n",
    "\n",
    "    f_esc = [2.3, -0.6, 3, 2.3, 17, 18, 12, 15, 14]\n",
    "    ne_esc = [0.8, 0.2, 1, 0.8, 6, 7, 5, 6, 5]\n",
    "\n",
    "    '''\n",
    "    # For each file\n",
    "    for i, file in enumerate(files):\n",
    "\n",
    "        # Join its folder path to the file name\n",
    "        file = ''.join([data, '/spectra/mage/', file])\n",
    "        files[i] = file\n",
    "    '''\n",
    "\n",
    "    #z = np.array([0, 0, 2.37086, 2.37073, 2.37021, 2.37025, 2.37014, 2.37017, 2.37044, \n",
    "    #2.37024, 2.37030], dtype=np.float64)\n",
    "    c_peak_range = np.array([[60,140],[20,130],[0,100],[0,85],[10,130],[35,120],[10,130],\n",
    "                             [45,125],[15,100],[25,125],[15,125]], dtype=np.float64)\n",
    "\n",
    "    total_result = np.array([np.empty((9,1000))])\n",
    "\n",
    "    mag = np.array([1.0, 1.0, 50.7, 14.6, 147.0, 36.1, 10.4, 31.6, 34.6, 29.4, 30.9], dtype=np.float64)\n",
    "\n",
    "    R = np.array([\n",
    "        299792.458 / 5400,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5500,\n",
    "        299792.458 / 5400,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5500,\n",
    "        299792.458 / 4700,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5200,\n",
    "        299792.458 / 5200,\n",
    "        299792.458 / 5500\n",
    "    ])\n",
    "\n",
    "    R_error = np.array([\n",
    "        299792.458 / 5400**2 * 200,\n",
    "        299792.458 / 5300**2 * 200,\n",
    "        299792.458 / 5500**2 * 400,\n",
    "        299792.458 / 5400**2 * 300,\n",
    "        299792.458 / 5300**2 * 300,\n",
    "        299792.458 / 5500**2 * 400,\n",
    "        299792.458 / 4700**2 * 200,\n",
    "        299792.458 / 5300**2 * 300,\n",
    "        299792.458 / 5200**2 * 200,\n",
    "        299792.458 / 5200**2 * 300,\n",
    "        299792.458 / 5500**2 * 400\n",
    "    ])\n",
    "\n",
    "    # For each spectrum\n",
    "    for i, slit_id in enumerate(slits):\n",
    "\n",
    "        z = slits[slit_id][1]\n",
    "        mag = slits[slit_id][2]\n",
    "        #model = slits[slit_id][3]\n",
    "        c_peak_range = slits[slit_id][3]\n",
    "\n",
    "        # Extract the data from the .txt file\n",
    "        w, f, n = extract_data(f'{data}/spectra/mage/{slits[slit_id][0]}')\n",
    "\n",
    "        f = f[(w >= 1195 * (1 + z)) & (w <= 1235 * (1 + z))]\n",
    "        n = n[(w >= 1195 * (1 + z)) & (w <= 1235 * (1 + z))]\n",
    "        w = w[(w >= 1195 * (1 + z)) & (w <= 1235 * (1 + z))]\n",
    "        \n",
    "        # Place the data in the rest frame\n",
    "        #w, f, n = rest_frame(w, f, n, z)\n",
    "        w = w / (1 + z)\n",
    "        f = f * (1 + z)\n",
    "        n = n * (1 + z)\n",
    "\n",
    "        v = 299792.458 * (w / 1215.67 - 1)\n",
    "\n",
    "        # Instantiate a cosmology with 30% matter-based energy density and an expansion rate of 70 km/s/Mpc\n",
    "        cosmology = FlatLambdaCDM(70,0.3)\n",
    "\n",
    "        # Determine the luminosity distance to the redshift in units of centimeters (to match the flux density unit)\n",
    "        l_dist = cosmology.luminosity_distance(z).value * 3.086e24\n",
    "\n",
    "        #fit_results, e_results, fcen_results, ratio_results, l_results = mc(w, v, f, n, z, c_peak_range[i], i)    \n",
    "\n",
    "        # Create a boolean mask designating the wavelength range used to compute the local continuum\n",
    "        cntm_mask = (w >= 1221) & (w <= 1225)\n",
    "\n",
    "        # Create a boolean mask designating the integration range when computing the equivalent width\n",
    "        ew_mask = (w >= 1212) & (w <= 1221)\n",
    "\n",
    "        # Create boolean masks for the integration ranges about the rest velocity of the Lya profile\n",
    "        # for computing the central escape fraction of the Lya profile\n",
    "        v100_mask = (v >= -100) & (v <= 100)\n",
    "        v1000_mask = (v >= -1000) & (v <= 1000)\n",
    "\n",
    "        # Mask for the observed-frame wavelength boundaries when computing the luminosity of the Lya profile\n",
    "        l_mask = (w >= 1212 * (1 + z)) & (w <= 1221 * (1 + z))\n",
    "\n",
    "        flux_density_unit = 'erg/s/cm^2/Å' if 'M' in slit_id else 'normalized wavelength-space flux density'\n",
    "\n",
    "        # If there is no blue peak\n",
    "        if i in [0,3,4]:\n",
    "        \n",
    "            model = two_peaks\n",
    "            model_parameter_labels = f'redshifted Lyα peak amplitude ({flux_density_unit}), centroid (km/s), width (km/s), and skew, \\n' \\\n",
    "                + f'central Lyα peak amplitude ({flux_density_unit}), centroid (km/s), and width (km/s), ' \\\n",
    "                + f'and local continuum ({flux_density_unit})'\n",
    "        \n",
    "            p0 = (np.amax(f[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]),80,40,np.median(f[cntm_mask]))\n",
    "            bounds = ([0,0,0,0,0,0,0,0],[np.amax(f),1000,np.inf,np.inf,np.amax(f),200,85,np.mean(f)])\n",
    "    \n",
    "        elif i in [2]:\n",
    "\n",
    "            model = two_peaks\n",
    "            model_parameter_labels = f'redshifted Lyα peak amplitude ({flux_density_unit}), centroid (km/s), width (km/s), and skew, \\n' \\\n",
    "                + f'central Lyα peak amplitude ({flux_density_unit}), centroid (km/s), and width (km/s), ' \\\n",
    "                + f'and local continuum ({flux_density_unit})'\n",
    "\n",
    "            p0 = (np.amax(f[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]) - np.median(f[cntm_mask]),50,20,np.median(f[cntm_mask]))\n",
    "            bounds = ([0,0,0,0,0,0,0,0],[np.amax(f),500,np.inf,np.inf,np.amax(f[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]) - np.median(f[cntm_mask]),100,40,np.amax(f)])\n",
    "\n",
    "        # Otherwise\n",
    "        else:\n",
    "\n",
    "            model = three_peaks\n",
    "            model_parameter_labels = f'blueshifted Lyα peak amplitude ({flux_density_unit}), centroid (km/s), width (km/s), and skew, \\n' \\\n",
    "                + f'redshifted Lyα peak amplitude ({flux_density_unit}), centroid (km/s), width (km/s), and skew, \\n' \\\n",
    "                + f'central Lyα peak amplitude ({flux_density_unit}), centroid (km/s), and width (km/s), ' \\\n",
    "                + f'and local continuum ({flux_density_unit})'\n",
    "\n",
    "            p0 = (np.amax(f[(v >= -1000) & (v <= 0)]),-150,20,-1,np.amax(f[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]),80,40,np.median(f[cntm_mask]))\n",
    "            bounds = ([0,-1000,0,-np.inf,0,0,0,0,0,0,0,0],[np.amax(f[(v >= -1000) & (v <= 0)]),0,np.inf,0,np.amax(f),1000,np.inf,np.inf,np.amax(f),200,85,np.mean(f)])\n",
    "\n",
    "        #parameters = np.array([[]], dtype=np.float64)\n",
    "        parameters = []\n",
    "\n",
    "        # For each iteration in the Monte Carlo simulation\n",
    "        for j in range(1000):\n",
    "\n",
    "            # Draw a randomly sampled spectrum from the original observation, assuming \n",
    "            # that the observed flux densities and associated uncertainties correspond \n",
    "            # to the mean and standard deviation of Gaussian distributions, respectively\n",
    "            f_mc = np.random.normal(f, n)\n",
    "\n",
    "            # Compute the local continuum as the median flux density between 1221 - 1225 Å in the rest frame\n",
    "            c = np.median(f_mc[cntm_mask])\n",
    "\n",
    "            # Compute the equivalent width of the Lya profile\n",
    "            ew = -1 * np.trapz(1 - (f / c)[ew_mask], w[ew_mask])\n",
    "\n",
    "            # Compute the central escape fraction of the Lya profile\n",
    "            f_cen = np.trapz(f[v100_mask], v[v100_mask]) / np.trapz(f[v1000_mask], v[v1000_mask]) * 100\n",
    "\n",
    "            # Compute the luminosity of the Lya profile\n",
    "            l = 4 * np.pi * np.trapz((f_mc / (1 + z) / mag)[l_mask] - c / (1 + z) / mag, (w * (1 + z))[l_mask]) * l_dist**2\n",
    "\n",
    "            p, _ = curve_fit(model, v, f_mc, p0=p0, bounds=bounds, maxfev=2000) \n",
    "\n",
    "            # Compute the ratio between the 'minimum' flux density between the redshifted and blueshifted Lya peaks \n",
    "            # (really taken as the amplitude of the central Lya peak; see paper for justifying details) and the local continuum\n",
    "            ratio = p[-4] / p[-1]\n",
    "\n",
    "            #parameters = np.append(parameters, np.array([[*p]]), axis=0)\n",
    "            parameters.append([*p])\n",
    "\n",
    "        parameters = np.array(parameters, dtype=np.float64)\n",
    "\n",
    "        fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * parameters.T[-2]\n",
    "\n",
    "        fwhm_r, loc_r = compute_fwhm_and_peak(model, parameters, R[i], R_error[i])\n",
    "\n",
    "        if i in [0,2,3,4]:\n",
    "\n",
    "            #fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * fit_results.T[6]\n",
    "            #fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * stdv_c_results\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_r, _ = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "        else:\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_b, loc_b = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_b_results = np.append(fwhm_b_results, fwhm_b)\n",
    "\n",
    "                fwhm_r, loc_r = compute_fwhm_and_peak(sample[4], sample[5], sample[6], sample[7], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "                vsep = abs(loc_r - loc_b)\n",
    "                vsep_results = np.append(vsep_results, vsep)\n",
    "\n",
    "        if not os.path.isdir(f'{results}/lya_fits/{slit_id}'):\n",
    "            os.makedirs(f'{results}/lya_fits/{slit_id}')\n",
    "\n",
    "        header = f'Best-fit parameters of the Lyα fits of {f\"slit {slit_id}\" if \"M\" in slit_id else slit_id}\\n' \\\n",
    "            + '\\n' \\\n",
    "            + f'Initial parameters: {p0}\\n' \\\n",
    "            + '\\n' \\\n",
    "            + f'Columns, from left to right: {model_parameter_labels}\\n'\n",
    "\n",
    "        np.savetxt(f'{results}/lya_fits/{slit_id}/{slit_id}_best_fit_lya_parameters.txt', np.array([*parameters]), header=header, delimiter=' ', encoding='utf-8')\n",
    "\n",
    "        median_fit = [np.median(e) for e in fit_results.T]\n",
    "\n",
    "        # Take the transpose of the results so that the rows\n",
    "        # are by parameter, not sample number\n",
    "        #fit_results = fit_results.T\n",
    "\n",
    "        '''\n",
    "        if i in [0,2,3,4]:\n",
    "            stdv_c_results = fit_results.T[6]\n",
    "            fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * stdv_c_results\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_c_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_r, _ = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "                fwhm_c, _ = compute_fwhm_and_peak(sample[4], sample[5], sample[6], 0, R[i], R_error[i])\n",
    "                fwhm_c_results = np.append(fwhm_c_results, fwhm_c)\n",
    "\n",
    "                if np.isnan(fwhm_c):\n",
    "                    print(i, fwhm_c)\n",
    "\n",
    "        else:\n",
    "            stdv_c_results = fit_results.T[10]\n",
    "            fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * stdv_c_results\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_c_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_b, loc_b = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_b_results = np.append(fwhm_b_results, fwhm_b)\n",
    "\n",
    "                fwhm_c, _ = compute_fwhm_and_peak(sample[8], sample[9], sample[10], 0, R[i], R_error[i])\n",
    "                fwhm_c_results = np.append(fwhm_c_results, fwhm_c)\n",
    "\n",
    "                if np.isnan(fwhm_c):\n",
    "                    print(i, fwhm_c)\n",
    "\n",
    "                fwhm_r, loc_r = compute_fwhm_and_peak(sample[4], sample[5], sample[6], sample[7], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "                vsep = abs(loc_r - loc_b)\n",
    "                vsep_results = np.append(vsep_results, vsep)\n",
    "        '''\n",
    "\n",
    "        fwhm_c_results = fwhm_c_results[~np.isnan(fwhm_c_results)]\n",
    "\n",
    "        # If the spectrum is one of the stacked spectra\n",
    "        if i < 2:\n",
    "\n",
    "            results = [vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results]\n",
    "            r = np.array([None,None,None,None,1,1,1])\n",
    "            tau = np.array([None,None,None,None,1,1,1])\n",
    "            rho = np.array([None,None,None,None,1,1,1])\n",
    "\n",
    "        # If the spectrum is not one of the stacked spectra\n",
    "        elif i > 1:\n",
    "\n",
    "            results = [vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42]\n",
    "            r = np.array([None,None,None,None,1,1,1,1])\n",
    "            tau = np.array([None,None,None,None,1,1,1,1])\n",
    "            rho = np.array([None,None,None,None,1,1,1,1])\n",
    "\n",
    "        # If the spectrum is not a stacked one\n",
    "        if i > 1:\n",
    "            # Create pseudo-measurements of the LyC escape fraction assuming the calculated value and standard deviation\n",
    "            # correspond to a Gaussian mean and standard deviation\n",
    "            fesc_results = np.random.normal(f_esc[i-2], ne_esc[i-2], 1000)\n",
    "\n",
    "        else:\n",
    "            fesc_results = np.empty(1000)\n",
    "            fesc_results[:] = np.nan\n",
    "\n",
    "        slit_result = np.array([np.empty(1000)])\n",
    "\n",
    "        for j, result in enumerate([vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42, fesc_results]):\n",
    "            \n",
    "            # Try to append any missing values as NaNs\n",
    "            try:\n",
    "                if len(result) < 1000:\n",
    "                    a = np.empty(1000 - len(result))\n",
    "                    a[:] = np.nan\n",
    "\n",
    "                    result = np.append(result, a)\n",
    "\n",
    "            # Unless the array has not been instantiated\n",
    "            except TypeError:\n",
    "                result = np.empty(1000)\n",
    "                result[:] = np.nan\n",
    "            \n",
    "            if (i == 6) and (j == 7):\n",
    "                result = np.empty(1000)\n",
    "                result[:] = np.nan\n",
    "\n",
    "            result = np.where(result != 0.0, result, np.nan)\n",
    "\n",
    "            slit_result = np.append(slit_result, np.array([result]), axis=0)\n",
    "\n",
    "        # Drop the first row since it is empty\n",
    "        slit_result = slit_result[1:]\n",
    "\n",
    "        total_result = np.append(total_result, np.array([slit_result]), axis=0)\n",
    "\n",
    "    total_result = total_result[1:]\n",
    "\n",
    "    r_locs = [[3,0,0,0,0,0,0,0],\n",
    "        [2,4,0,0,0,0,0,0],\n",
    "        [1,1,2,0,0,0,0,0],\n",
    "        [3,3,2,7,0,0,0,0],\n",
    "        [3,3,2,7,2,0,0,0],\n",
    "        [3,3,2,7,2,2,1,1],\n",
    "        [3,3,2,1,2,2,2,1],\n",
    "        [2,'center left',2,4,2,2,2,2]]\n",
    "\n",
    "    # For each row in the corner plot\n",
    "    for i, row in enumerate(ax_c):\n",
    "\n",
    "        # For each column in the corner plot\n",
    "        for j, subplot in enumerate(row):\n",
    "\n",
    "            r_results = np.array([], dtype=np.float64)\n",
    "            tau_results = np.array([], dtype=np.float64)\n",
    "            rho_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            # If the row / column pair is above the main diagonal\n",
    "            if j > i:\n",
    "                pass\n",
    "            else:\n",
    "\n",
    "                x_data = np.empty(1000)\n",
    "                x_data[:] = np.nan\n",
    "                x_data = np.array([x_data])\n",
    "                y_data = np.empty(1000)\n",
    "                y_data[:] = np.nan\n",
    "                y_data = np.array([y_data])\n",
    "\n",
    "                # For each spectrum\n",
    "                for k, slit in enumerate(total_result):\n",
    "                    \n",
    "                    if all(np.isnan(slit[j])) or all(np.isnan(slit[i + 1])):\n",
    "                        pass\n",
    "                    else:\n",
    "\n",
    "                        x_data = np.append(x_data, np.array([slit[j]]), axis=0)\n",
    "                        y_data = np.append(y_data, np.array([slit[i + 1]]), axis=0)\n",
    "\n",
    "                x_data = x_data[1:]\n",
    "                y_data = y_data[1:]\n",
    "\n",
    "\n",
    "                if (i==6) and (j==6):\n",
    "                    pass\n",
    "\n",
    "                for k, sample in enumerate(x_data[0]):\n",
    "\n",
    "                    x = x_data[:,k]\n",
    "                    y = y_data[:,k]\n",
    "\n",
    "                    if any(np.isnan(x)) or any(np.isnan(y)):\n",
    "                        pass\n",
    "                    else:\n",
    "                        x = x[x != 0]\n",
    "                        y = y[y != 0]\n",
    "\n",
    "                        r = np.corrcoef(x, y)[0,1]\n",
    "                        tau = kendalltau(x, y).statistic\n",
    "                        rho = spearmanr(x, y).statistic\n",
    "\n",
    "                        r_results = np.append(r_results, r)\n",
    "                        tau_results = np.append(tau_results, tau)\n",
    "                        rho_results = np.append(rho_results, rho)\n",
    "\n",
    "def plot():\n",
    "    pass\n",
    "\n",
    "def tabulate():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8979a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "[[5408, 9501], [5588, 9337], [5607, 9326], [5402, 9449], [5810, 9014], [5586, 9419], [5398, 9500], [5370, 9445], [5393, 9454], [5604, 9425], [5375, 9429], [5392, 9446], [5367, 9488], [5537, 9524], [5551, 9452], [5628, 9358], [5402, 9452], [5405, 9460], [5373, 9414], [5437, 9491], [5573, 9454], [5501, 9471], [5381, 9494], [5434, 9356], [5387, 9423], [5641, 9347], [5578, 9390], [5439, 9435], [5385, 9506], [5402, 9430], [5449, 9418], [5371, 9511], [5377, 9494], [5402, 9480], [5501, 9514], [5420, 9495], [5377, 9527], [5571, 9407], [5415, 9476], [5546, 9449], [5629, 9334], [5360, 9483], [5596, 9438], [5380, 9431], [5528, 9458], [5523, 9463], [5412, 9475], [5382, 9462], [5397, 9428], [5393, 9398], [5589, 9374], [5380, 9455], [5549, 9476], [5498, 9539], [5384, 9474], [5378, 9431], [5685, 9167], [5396, 9413], [5391, 9469], [5401, 9447], [5361, 9466], [5381, 9506], [5368, 9505], [5374, 9475], [5446, 9383], [5380, 9492], [5412, 9441], [5649, 9272], [5460, 9419], [5600, 9358], [5623, 9329], [5636, 9392], [5571, 9339], [5398, 9483], [5383, 9387], [5405, 9449], [5455, 9396], [5411, 9468], [5382, 9386], [5417, 9524], [5588, 9396], [5396, 9426], [5510, 9529], [5415, 9484], [5624, 9252], [5622, 9310], [5516, 9456], [5580, 9403], [5543, 9519], [5420, 9453], [5358, 9496], [5420, 9426], [5430, 9414], [5361, 9504], [5608, 9391], [5388, 9379], [5593, 9334], [5388, 9457], [5380, 9401], [5530, 9484], [5594, 9373], [5605, 9371], [5595, 9343], [5634, 9354], [5526, 9475], [5543, 9479], [5395, 9454], [5606, 9331], [5367, 9442], [5383, 9496], [5651, 9276], [5589, 9351], [5501, 9539], [5600, 9394], [5558, 9492], [5390, 9414], [5395, 9448], [5607, 9413], [5369, 9491], [5416, 9431], [5402, 9419], [5353, 9443], [5582, 9408], [5405, 9404], [5385, 9459], [5395, 9464], [5573, 9439], [5329, 9477], [5633, 9335], [5392, 9450], [5396, 9490], [5594, 9400], [5397, 9485], [5563, 9476], [5371, 9440], [5368, 9504], [5419, 9436], [5458, 9465], [5502, 9487], [5394, 9406], [5381, 9446], [5610, 9383], [5380, 9489], [5383, 9473], [5416, 9425], [5357, 9432], [5613, 9359], [5569, 9397], [5364, 9449], [5533, 9453], [5398, 9405], [5394, 9443], [5618, 9338], [5381, 9384], [5554, 9433], [5578, 9364], [5512, 9501], [5411, 9440], [5369, 9419], [5559, 9447], [5770, 9028], [5580, 9433], [5591, 9382], [5524, 9486], [5415, 9435], [5416, 9479], [5623, 9314], [5414, 9431], [5556, 9461], [5364, 9487], [5387, 9475], [5595, 9376], [5580, 9363], [5412, 9431], [5375, 9453], [5381, 9530], [5393, 9446], [5402, 9434], [5458, 9412], [5360, 9456], [5396, 9415], [5640, 9284], [5425, 9462], [5379, 9457], [5381, 9466], [5423, 9433], [5349, 9466], [5411, 9443], [5397, 9424], [5381, 9506], [5395, 9377], [5551, 9466], [5362, 9431], [5618, 9351], [5612, 9305], [5403, 9386], [5591, 9393], [5400, 9375], [5372, 9423], [5462, 9406], [5419, 9459], [5392, 9433], [5399, 9463], [5419, 9476], [5564, 9450], [5546, 9371], [5373, 9432], [5631, 9342], [5521, 9490], [5396, 9430], [5556, 9421], [5536, 9449], [5420, 9433], [5390, 9433], [5597, 9371], [5554, 9423], [5421, 9476], [5581, 9451], [5510, 9482], [5514, 9491], [5615, 9334], [5606, 9340], [5415, 9368], [5374, 9419], [5587, 9392], [5595, 9353], [5382, 9466], [5402, 9427], [5407, 9446], [5412, 9391], [5372, 9455], [5393, 9468], [5386, 9382], [5389, 9420], [5428, 9462], [5453, 9428], [5400, 9482], [5703, 9170], [5497, 9499], [5407, 9451], [5614, 9383], [5411, 9400], [5669, 8884], [5364, 9462], [5396, 9471], [5359, 9430], [5335, 9490], [5566, 9388], [5421, 9421], [5394, 9470], [5563, 9432], [5578, 9395], [5396, 9485], [5611, 9373], [5572, 9413], [5495, 9523], [5369, 9465], [5576, 9447], [5531, 9505], [5404, 9424], [5408, 9479], [5539, 9444], [5411, 9431], [5414, 9355], [5449, 9433], [5613, 9362], [5601, 9411], [5386, 9380], [5567, 9454], [5618, 9354], [5368, 9457], [5614, 9356], [5426, 9425], [5577, 9396], [5643, 9387], [5411, 9444], [5596, 9430], [5401, 9410], [5405, 9395], [5618, 9320], [5407, 9458], [5571, 9372], [5349, 9406], [5527, 9537], [5599, 9310], [5377, 9451], [5365, 9479], [5599, 9420], [5409, 9440], [5371, 9427], [5379, 9376], [5607, 9394], [5590, 9425], [5426, 9353], [5390, 9400], [5545, 9488], [5410, 9476], [5612, 9380], [5355, 9472], [5557, 9472], [5610, 9350], [5382, 9452], [5416, 9442], [5758, 9090], [5413, 9378], [5438, 9404], [5374, 9516], [5386, 9478], [5368, 9406], [5412, 9484], [5583, 9338], [5371, 9405], [5385, 9438], [5537, 9465], [5450, 9449], [5564, 9437], [5417, 9403], [5366, 9501], [5397, 9422], [5608, 9365], [5388, 9459], [5405, 9438], [5398, 9487], [5611, 9394], [5432, 9346], [5363, 9487], [5605, 9414], [5554, 9387], [5573, 9398], [5525, 9490], [5662, 9314], [5649, 9278], [6068, 8537], [5525, 9491], [5371, 9442], [5505, 9479], [5553, 9406], [5378, 9390], [5420, 9489], [5410, 9432], [5787, 8983], [5379, 9388], [5626, 9346], [5518, 9458], [5389, 9430], [5393, 9418], [5426, 9373], [5375, 9387], [5393, 9463], [5385, 9488], [5639, 9287], [5388, 9495], [5376, 9489], [5585, 9408], [5370, 9470], [5556, 9479], [5391, 9425], [5357, 9508], [5576, 9438], [5425, 9467], [5552, 9409], [5551, 9409], [5365, 9420], [5383, 9447], [5378, 9468], [5396, 9453], [5390, 9471], [5598, 9323], [5419, 9413], [5389, 9411], [5378, 9417], [5617, 9366], [5380, 9393], [5381, 9424], [5571, 9397], [5381, 9421], [5410, 9451], [5544, 9448], [5576, 9375], [5565, 9467], [5586, 9399], [5525, 9493], [5421, 9407], [5430, 9431], [5668, 9236], [5590, 9407], [5424, 9441], [5617, 9335], [5381, 9494], [5379, 9459], [5420, 9464], [5370, 9451], [5376, 9429], [5351, 9488], [5409, 9441], [5405, 9435], [5578, 9437], [5369, 9483], [5572, 9407], [5396, 9495], [5417, 9448], [5544, 9437], [5399, 9470], [5607, 9448], [5467, 9430], [5514, 9462], [5359, 9457], [5386, 9417], [5435, 9417], [5597, 9320], [5433, 9369], [5581, 9380], [5572, 9440], [5572, 9406], [5429, 9392], [5427, 9468], [5541, 9534], [5632, 9380], [5522, 9484], [5382, 9395], [5599, 9388], [5548, 9445], [5407, 9418], [5574, 9455], [5394, 9472], [5372, 9431], [5604, 9383], [5407, 9412], [5372, 9392], [5406, 9409], [5335, 9489], [5539, 9436], [5403, 9441], [5373, 9372], [5623, 9294], [5365, 9427], [5600, 9391], [5620, 9296], [5409, 9473], [5435, 9431], [5587, 9362], [5391, 9410], [5377, 9513], [5582, 9383], [5552, 9454], [5531, 9479], [5392, 9360], [5600, 9383], [5413, 9484], [5590, 9446], [5603, 9356], [5398, 9514], [5403, 9431], [5649, 9284], [5511, 9521], [5414, 9423], [5405, 9419], [5370, 9459], [5388, 9450], [5582, 9364], [5556, 9408], [5382, 9465], [5395, 9460], [5417, 9452], [5375, 9458], [5523, 9481], [5389, 9473], [5411, 9370], [5614, 9354], [5397, 9406], [5373, 9442], [5431, 9436], [5519, 9514], [5457, 9417], [5580, 9415], [5423, 9501], [5608, 9381], [5391, 9482], [5413, 9435], [5627, 9298], [5595, 9346], [5596, 9358], [5373, 9405], [5614, 9340], [5385, 9455], [5399, 9465], [5328, 9469], [5589, 9386], [5391, 9490], [5362, 9488], [5582, 9371], [5420, 9454], [5546, 9418], [5381, 9413], [5398, 9449], [5639, 9310], [5388, 9456], [5527, 9556], [5580, 9393], [5360, 9512], [5398, 9475], [5381, 9386], [5420, 9403], [5365, 9419], [5495, 9540], [5437, 9405], [5400, 9395], [5548, 9461], [5486, 9539], [5755, 9145], [5581, 9404], [5770, 9005], [5472, 9438], [5558, 9470], [5349, 9424], [5419, 9405], [5565, 9439], [5414, 9368], [5603, 9335], [5370, 9463], [5386, 9453], [5381, 9443], [5380, 9498], [5410, 9412], [5368, 9434], [5402, 9488], [5397, 9466], [5598, 9398], [5573, 9410], [5593, 9339], [5550, 9424], [5363, 9447], [5371, 9449], [5378, 9479], [5573, 9356], [5381, 9420], [5375, 9439], [5390, 9348], [5550, 9487], [5554, 9421], [5602, 9416], [5405, 9464], [5370, 9472], [5629, 9324], [5443, 9421], [5350, 9482], [5346, 9457], [5375, 9430], [5365, 9440], [5595, 9452], [5573, 9415], [5362, 9371], [5384, 9548], [5406, 9477], [5447, 9516], [5445, 9381], [5391, 9455], [5381, 9445], [5641, 9293], [5426, 9459], [5408, 9478], [5364, 9453], [5550, 9443], [5344, 9415], [5376, 9405], [5628, 9323], [5364, 9439], [5391, 9464], [5378, 9427], [5455, 9452], [5395, 9454], [5408, 9442], [5462, 9392], [5366, 9467], [5517, 9451], [5390, 9476], [5383, 9497], [5415, 9438], [5592, 9366], [5564, 9378], [5556, 9465], [5350, 9524], [5386, 9465], [5587, 9431], [5535, 9510], [5827, 9000], [5466, 9492], [5407, 9437], [5413, 9524], [5584, 9354], [5409, 9477], [5516, 9486], [5373, 9449], [5605, 9337], [5679, 5854], [5386, 9456], [5411, 9486], [5381, 9410], [5579, 9346], [5386, 9424], [5414, 9486], [5440, 9396], [5370, 9400], [5397, 9410], [5373, 9487], [5370, 9420], [5603, 9362], [5379, 9384], [5512, 9469], [5387, 9504], [5434, 9468], [5409, 9491], [5595, 9350], [5405, 9517], [5507, 9532], [5399, 9451], [5352, 9526], [5391, 9496], [5390, 9450], [5550, 9485], [5408, 9450], [5339, 9429], [5350, 9541], [5547, 9439], [5355, 9462], [5403, 9445], [5409, 9423], [5356, 9446], [5424, 9463], [5582, 9395], [5357, 9473], [5389, 9397], [5530, 9519], [5620, 9328], [5386, 9434], [5380, 9395], [5371, 9482], [5389, 9434], [5389, 9386], [5424, 9448], [5388, 9499], [5535, 9467], [5507, 9507], [5417, 9415], [5578, 9366], [5393, 9470], [5431, 9404], [5418, 9414], [5510, 9506], [5654, 9319], [5405, 9419], [5628, 9273], [5424, 9414], [5398, 9497], [5629, 9355], [5409, 9511], [5373, 9476], [5612, 9355], [5396, 9397], [5432, 9444], [5393, 9504], [5392, 9433], [5365, 9424], [5566, 9407], [5588, 9456], [5614, 9387], [5439, 9399], [5594, 9395], [5406, 9430], [5387, 9423], [5369, 9452], [5377, 9530], [5431, 9405], [5395, 9437], [5390, 9487], [5368, 9450], [5384, 9365], [5522, 9506], [5395, 9392], [5382, 9473], [5417, 9456], [5390, 9429], [5589, 9415], [5416, 9412], [5573, 9412], [5414, 9447], [5411, 9405], [5605, 9364], [5827, 8902], [5546, 9419], [5414, 9481], [5370, 9470], [5373, 9441], [5412, 9417], [5422, 9450], [5387, 9444], [5402, 9394], [5370, 9492], [5540, 9410], [5413, 9444], [5438, 9398], [5395, 9413], [5574, 9350], [5470, 9506], [5607, 9416], [5584, 9408], [5545, 9403], [5607, 9397], [5577, 9314], [5402, 9384], [5354, 9475], [5406, 9422], [5400, 9431], [5635, 9316], [5553, 9420], [5378, 9489], [5432, 9492], [5570, 9437], [5634, 9357], [5579, 9395], [5394, 9462], [5364, 9458], [5386, 9455], [5498, 9477], [5637, 9323], [5330, 9490], [5380, 9470], [5403, 9485], [5397, 9402], [5574, 9474], [5555, 9466], [5607, 9330], [5378, 9470], [5390, 9465], [5548, 9443], [5392, 9416], [5367, 9438], [5551, 9429], [5406, 9412], [5557, 9390], [5395, 9421], [5549, 9411], [5408, 9463], [5614, 9311], [5394, 9526], [5401, 9472], [5567, 9440], [5408, 9422], [5339, 9513], [5595, 9362], [5567, 9397], [5364, 9458], [5388, 9416], [5383, 9451], [5366, 9430], [5417, 9413], [5405, 9475], [5618, 9406], [5539, 9518], [5598, 9383], [5363, 9505], [5364, 9477], [5515, 9501], [5608, 9356], [5589, 9415], [5582, 9409], [5588, 9359], [5393, 9443], [5378, 9474], [5604, 9324], [5603, 9351], [5367, 9473], [5596, 9416], [5557, 9521], [5401, 9433], [5611, 9423], [5490, 9495], [5407, 9423], [5394, 9438], [5423, 9428], [5370, 9462], [5561, 9375], [5529, 9500], [5383, 9421], [5381, 9508], [5748, 9132], [5367, 9437], [5615, 9263], [5388, 9452], [5407, 9469], [5376, 9521], [5398, 9524], [5411, 9464], [5531, 9490], [5574, 9402], [5567, 9432], [5531, 9469], [5396, 9426], [5454, 9436], [5391, 9429], [5424, 9429], [5631, 9260], [5367, 9419], [5417, 9377], [5441, 9429], [5377, 9534], [5379, 9472], [5429, 9437], [5425, 9453], [5418, 9430], [5400, 9440], [5375, 9474], [5419, 9435], [5556, 9385], [5371, 9428], [5550, 9417], [5578, 9454], [5401, 9473], [5408, 9461], [5450, 9418], [5534, 9467], [5546, 9429], [5600, 9393], [5426, 9368], [5383, 9416], [5385, 9428], [5362, 9466], [5574, 9448], [5380, 9465], [5370, 9468], [5606, 9353], [5426, 9397], [5382, 9511], [5358, 9473], [5607, 9375], [5612, 9486], [5484, 9495], [5401, 9403], [5389, 9443], [5396, 9435], [5452, 9408], [5365, 9497], [5564, 9377], [5372, 9433], [5605, 9345], [5543, 9507], [5425, 9404], [5539, 9455], [5406, 9451], [5558, 9406], [5415, 9390], [5358, 9492], [5417, 9428], [5625, 9322], [5380, 9437], [5603, 9412], [5584, 9359], [5402, 9448], [5521, 9471], [5606, 9288], [5420, 9469], [5384, 9484], [5607, 9311], [5600, 9441], [5534, 9490], [5614, 9399], [5406, 9420], [5384, 9493], [5553, 9499], [6333, 6362], [5576, 9378], [5394, 9444], [5420, 9435], [5375, 9485], [5379, 9458], [5412, 9434], [5381, 9479], [5425, 9393], [5610, 9407], [5582, 9420], [5393, 9464], [5432, 9401], [5364, 9430], [5507, 9504], [5581, 9363], [5569, 9463], [5557, 9422], [5567, 9487], [5375, 9495], [5377, 9504], [5409, 9444], [5343, 9506], [5518, 9493], [5401, 9393], [5374, 9474], [5363, 9530], [5390, 9455], [5417, 9444], [5381, 9525], [5332, 9456], [5390, 9386], [5397, 9469], [5362, 9400], [5405, 9415], [5351, 9523], [6022, 8506], [5367, 9509], [5374, 9445], [5387, 9481], [5585, 9412], [5432, 9441], [5509, 9503], [5612, 9367], [5490, 9467], [5575, 9401], [5379, 9449], [5404, 9398], [5333, 9512], [5408, 9453], [5344, 9513], [5421, 9455], [5390, 9462], [5375, 9468], [5549, 9462], [5405, 9439], [5555, 9436], [5566, 9358], [5577, 9421], [5366, 9446], [5383, 9485], [5374, 9416], [5380, 9467], [5349, 9428], [5402, 9464], [5394, 9395], [5364, 9433], [5055, 5058], [5566, 9373], [5564, 9372], [5563, 9361], [5359, 9508], [5350, 9488], [5451, 9448], [5601, 9327], [5405, 9503], [5602, 9397], [5355, 9448], [5427, 9446], [5403, 9449], [5355, 9416], [5387, 9505], [5416, 9374], [5413, 9434], [5423, 9431], [5373, 9462], [5424, 9387], [5341, 9495], [5377, 9394], [5392, 9468], [5391, 9395], [5403, 9486], [5419, 9424], [5383, 9463], [5418, 9421], [5365, 9418], [5512, 9506], [5375, 9482], [5613, 9385], [5360, 9499], [5525, 9435], [5532, 9509], [5391, 9472], [5398, 9459], [5574, 9369], [5613, 9345], [5599, 9386], [5427, 9382], [5553, 9463], [5539, 9457], [5561, 9411], [5449, 9399], [5361, 9377], [5514, 9493], [5562, 9489], [5382, 9437], [5577, 9423], [5411, 9452], [5368, 9462], [5340, 9531], [5595, 9355], [5422, 9420], [5354, 9418], [5423, 9436], [5386, 9468], [5449, 9365], [5511, 9503], [5575, 9418], [5425, 9458], [5589, 9404], [5586, 9433]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15136\\AppData\\Local\\Temp/ipykernel_18716/2139069490.py:123: RuntimeWarning: invalid value encountered in sqrt\n",
      "  fwhms = np.sqrt((np.array(fwhms))**2 - (res)**2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fit_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18716/2806096226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmeasure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18716/2139069490.py\u001b[0m in \u001b[0;36mmeasure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mvsep_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mfwhm_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_fwhm_and_peak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR_error\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_results' is not defined"
     ]
    }
   ],
   "source": [
    "measure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a888e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file):\n",
    "\n",
    "    '''\n",
    "    Extract spectrum from the .txt file\n",
    "\n",
    "    Parameters:\n",
    "        file : str\n",
    "            Name of the file\n",
    "\n",
    "    Returns:\n",
    "        w : numpy.ndarray\n",
    "            Observed wavelength bins\n",
    "        f : numpy.ndarray\n",
    "            Observed flux densities\n",
    "        n : numpy.ndarray\n",
    "            Observed Gaussian standard deviation of observed flux densities\n",
    "    '''\n",
    "\n",
    "    # Retrieve the data columns\n",
    "    w, f, n = np.loadtxt(file, delimiter='\\t', comments=('#', 'w'), usecols=(0,1,2), unpack=True)\n",
    "    \n",
    "    # If the file is not the stacked leaker spectrum. This step is necessary because \n",
    "    if 'leaker' not in file:\n",
    "\n",
    "        # Remove bins of extreme outliers\n",
    "        w = w[f < 1e-20]\n",
    "        n = n[f < 1e-20]\n",
    "        f = f[f < 1e-20]\n",
    "\n",
    "        # Convert from units of erg/s/cm^2/Hz to erg/s/cm^2/Å\n",
    "        f = f * 2.998e18 / np.square(w)\n",
    "        n = n * 2.998e18 / np.square(w)\n",
    "\n",
    "    return w, f, n    \n",
    "\n",
    "@njit\n",
    "def rest_frame(w, f, n, z):\n",
    "\n",
    "    '''\n",
    "    Place the data in the rest frame\n",
    "\n",
    "    Parameters:\n",
    "        w : numpy.ndarray\n",
    "            Observed wavelength bins\n",
    "        f : numpy.ndarray\n",
    "            Observed flux densities\n",
    "        n : numpy.ndarray\n",
    "            Gaussian standard deviation of observed flux densities\n",
    "        z : numpy.float64\n",
    "            Redshift of the spectrum\n",
    "\n",
    "    Returns:\n",
    "        w : numpy.ndarray\n",
    "            Rest wavelength bins\n",
    "        f : numpy.ndarray\n",
    "            Rest flux densities\n",
    "        n : numpy.ndarray\n",
    "            Gaussian standard deviation of rest flux densities\n",
    "    '''\n",
    "\n",
    "    w = w / (1 + z)\n",
    "    f = f * (1 + z)\n",
    "    n = n * (1 + z)\n",
    "\n",
    "    return w, f, n\n",
    "\n",
    "def compute_continuum(w, f):\n",
    "\n",
    "    '''\n",
    "    Compute the local continuum\n",
    "\n",
    "    Parameters:\n",
    "        w : numpy.ndarray\n",
    "            Rest wavelength\n",
    "        f : numpy.ndarray\n",
    "            Rest flux density\n",
    "\n",
    "    Returns:\n",
    "        c : numpy.float64\n",
    "            Local continuum flux density\n",
    "    '''\n",
    "\n",
    "    # Compute the local continuum as the\n",
    "    # median flux density between 1221-1225 Å\n",
    "    f = f[(w >= 1221) & (w <= 1225)]\n",
    "    c = np.median(f)    \n",
    "\n",
    "    return c\n",
    "\n",
    "@njit\n",
    "def compute_ew(w, f, c, results):\n",
    "\n",
    "    '''\n",
    "    Compute the EW of the Lyα profile\n",
    "\n",
    "    Parameters:\n",
    "        w : numpy.ndarray\n",
    "            Rest wavelength\n",
    "        f : numpy.ndarray\n",
    "            Rest flux density\n",
    "        c : numpy.float64\n",
    "            Local continuum flux density\n",
    "        results : numpy.ndarray\n",
    "            Array containing measurements\n",
    "\n",
    "    Returns:\n",
    "        ew : numpy.float64\n",
    "            Equivalent width\n",
    "    '''\n",
    "\n",
    "    # Compute the EW of the Lyα profile\n",
    "    # between 1212-1221 Å\n",
    "    f = f[(w >= 1212) & (w <= 1221)]\n",
    "    w = w[(w >= 1212) & (w <= 1221)]\n",
    "    ew = -1 * np.trapz(1 - f / c, w)\n",
    "\n",
    "    results = np.append(results, ew)\n",
    "\n",
    "    return results\n",
    "\n",
    "@njit\n",
    "def compute_fcen(v, f, results):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    # Compute the central escape fraction as a percent\n",
    "    f_cen = np.trapz(f[(v >= -100) & (v <= 100)], v[(v >= -100) & (v <= 100)]) / np.trapz(f[(v >= -1000) & (v <= 1000)], v[(v >= -1000) & (v <= 1000)]) * 100\n",
    "    results = np.append(results, f_cen)\n",
    "\n",
    "    return results\n",
    "\n",
    "def compute_l(w, f_mc, c, z, l_distance, l_results):\n",
    "\n",
    "    f_mc = f_mc[(w >= 1212 * (1 + z)) & ((w <= 1221 * (1 + z)))]\n",
    "    w = w[(w >= 1212 * (1 + z)) & ((w <= 1221 * (1 + z)))]\n",
    "\n",
    "    flux = np.trapz(f_mc - c, w)\n",
    "\n",
    "    l = 4 * np.pi * flux * l_distance**2\n",
    "    l_results = np.append(l_results, l)\n",
    "\n",
    "    return l_results\n",
    "\n",
    "\n",
    "def compute_ratio(v, f_mc, c, c_peak_range, ratio_results):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    ratio = np.amax(f_mc[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]) / c\n",
    "    ratio_results = np.append(ratio_results, ratio)\n",
    "\n",
    "    return ratio_results\n",
    "\n",
    "def fit_peaks(v, f_mc, c, c_peak_range, model, i):\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    # If there is no blue peak\n",
    "    if i in [0,3,4]:\n",
    "        \n",
    "        # Assign the initial guess and parameter bounds; this must be done inside the Monte Carlo loop to get the best initial\n",
    "        # estimates so they can be built from the random sample\n",
    "        p0 = (np.amax(f_mc[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f_mc[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]),80,40,c)\n",
    "        bounds = ([0,0,0,0,0,0,0,0],[np.amax(f_mc),1000,np.inf,np.inf,np.amax(f_mc),200,85,np.mean(f_mc)])\n",
    "    \n",
    "    elif i in [2]:\n",
    "\n",
    "        # Assign the initial guess and parameter bounds; this must be done inside the Monte Carlo loop to get the best initial\n",
    "        # estimates so they can be built from the random sample\n",
    "        p0 = (np.amax(f_mc[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f_mc[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]) - c,50,20,c)\n",
    "        bounds = ([0,0,0,0,0,0,0,0],[np.amax(f_mc),500,np.inf,np.inf,np.amax(f_mc[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]) - c,100,40,np.amax(f_mc)])\n",
    "\n",
    "    # Otherwise\n",
    "    else:\n",
    "\n",
    "        # Assign the initial guess and parameter bounds; this must be done inside the Monte Carlo loop to get the best initial\n",
    "        # estimates so they can be built from the random sample\n",
    "        p0 = (np.amax(f_mc[(v >= -1000) & (v <= 0)]),-150,20,-1,np.amax(f_mc[(v >= 150) & (v <= 1000)]),200,20,1,np.amax(f_mc[(v >= c_peak_range[0]) & (v <= c_peak_range[1])]),80,40,c)\n",
    "        bounds = ([0,-1000,0,-np.inf,0,0,0,0,0,0,0,0],[np.amax(f_mc[(v >= -1000) & (v <= 0)]),0,np.inf,0,np.amax(f_mc),1000,np.inf,np.inf,np.amax(f_mc),200,85,np.mean(f_mc)])\n",
    "\n",
    "    p, cov = curve_fit(model, v, f_mc, p0=p0, bounds=bounds, maxfev=2000)\n",
    "\n",
    "    return p, cov\n",
    "\n",
    "def mc(w, v, f, n, z, c_peak_range, i):\n",
    "\n",
    "    '''\n",
    "    Parameters:\n",
    "        w : numpy.ndarray\n",
    "        f : numpy.ndarray\n",
    "        n : numpy.ndarray\n",
    "    '''\n",
    "\n",
    "    def two_peaks(x, amp_r, cen_r, width_r, skew_r, amp_c, cen_c, width_c, cntm):\n",
    "\n",
    "        return amp_r * np.exp(-((x - cen_r) / width_r)**2 / 2) * (1 + erf(skew_r * ((x - cen_r) / width_r) / np.sqrt(2))) \\\n",
    "            + amp_c * np.exp(-((x - cen_c) / width_c)**2 / 2) \\\n",
    "            + cntm\n",
    "\n",
    "    def three_peaks(x, amp_b, cen_b, width_b, skew_b, amp_r, cen_r, width_r, skew_r, amp_c, cen_c, width_c, cntm):\n",
    "\n",
    "        return amp_b * np.exp(-((x - cen_b) / width_b)**2 / 2) * (1 + erf(skew_b * ((x - cen_b) / width_b) / np.sqrt(2)))  \\\n",
    "            + amp_r * np.exp(-((x - cen_r) / width_r)**2 / 2) * (1 + erf(skew_r * ((x - cen_r) / width_r) / np.sqrt(2))) \\\n",
    "            + amp_c * np.exp(-((x - cen_c) / width_c)**2 / 2) \\\n",
    "            + cntm\n",
    "\n",
    "    cosmology=FlatLambdaCDM(70,0.3)\n",
    "    l_distance = cosmology.luminosity_distance(z).value * 3.086e24\n",
    "\n",
    "    # If there is no blue peak\n",
    "    if i in [0,2,3,4]:\n",
    "        model = two_peaks\n",
    "        fit_results = np.empty((1,8), dtype=np.float64)\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "        model = three_peaks\n",
    "        fit_results = np.empty((1,12), dtype=np.float64)\n",
    "\n",
    "    if i > 1:\n",
    "        f = f * 1e17\n",
    "        n = n * 1e17\n",
    "\n",
    "    mag = np.array([1.0, 1.0, 50.7, 14.6, 147.0, 36.1, 10.4, 31.6, 34.6, 29.4, 30.9], dtype=np.float64)\n",
    "\n",
    "    e_results = np.array([], dtype=np.float64)\n",
    "    fcen_results = np.array([], dtype=np.float64)\n",
    "    l_results = np.array([], dtype=np.float64)\n",
    "    ratio_results = np.array([], dtype=np.float64)\n",
    "\n",
    "    for s in range(1000):\n",
    "\n",
    "        f_mc = np.random.normal(f, n)\n",
    "\n",
    "        c = compute_continuum(w, f_mc)\n",
    "\n",
    "        e_results = compute_ew(w, f_mc, c, e_results)\n",
    "\n",
    "        fcen_results = compute_fcen(v, f_mc, fcen_results)\n",
    "\n",
    "        l_results = compute_l(w * (1 + z), f_mc * 1e-17 / (1 + z) / mag[i], c * 1e-17 / (1 + z) / mag[i], z, l_distance, l_results)    \n",
    "\n",
    "        #ratio_results = compute_ratio(v, f_mc, c, c_peak_range, ratio_results)\n",
    "\n",
    "        try:\n",
    "\n",
    "            p, _ = fit_peaks(v[(v >= -1000) & (v <= 1000) & (f_mc >= c)], f_mc[(v >= -1000) & (v <= 1000) & (f_mc >= c)], c, c_peak_range, model, i)\n",
    "            \n",
    "            ratio_results = np.append(ratio_results, p[-4] / p[-1])\n",
    "            \n",
    "            fit_results = np.append(fit_results, np.array([p]), axis=0)\n",
    "\n",
    "            '''\n",
    "            if i==0:\n",
    "\n",
    "                fig, ax = plt.subplots()  \n",
    "\n",
    "                ax.plot(v, f_mc, ds='steps-mid', color='black')\n",
    "                ax.plot(v, model(v, *p), ls='dashed', color='red')\n",
    "                ax.set_xlim(-1000,1000)\n",
    "                plt.show()\n",
    "            '''\n",
    "\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "\n",
    "    # Remove the first empty row that was created\n",
    "    # when the array was initialized\n",
    "    fit_results = fit_results[1:]\n",
    "\n",
    "    for i, parameter in enumerate(fit_results.T):\n",
    "\n",
    "        #print(f'$np.median(parameter)_-{abs(np.median(parameter) - np.percentile(parameter, 16))}r}^r{+{abs(np.percentile(parameter, 84) - np.median(parameter))}r}$')\n",
    "        print('$' + str(np.median(parameter)) + \\\n",
    "            '_{-' + str(sf_round(abs(np.median(parameter) - np.percentile(parameter, 16)),1)) + '}' + \\\n",
    "            '^{+' + str(sf_round(abs(np.percentile(parameter, 84) - np.median(parameter)),1)) + '}' + \\\n",
    "            '$')\n",
    "\n",
    "    return fit_results, e_results, fcen_results, ratio_results, l_results\n",
    "\n",
    "def compute_fwhm_and_peak(amp, cen, width, skew, R, R_error):\n",
    "\n",
    "    '''\n",
    "    Returns:\n",
    "        fwhm : numpy.float64\n",
    "        loc : numpy.float64\n",
    "    '''\n",
    "    def lin_interp(x, y, i, half):\n",
    "        return x[i] + (x[i+1] - x[i]) * ((half - y[i]) / (y[i+1] - y[i]))\n",
    "\n",
    "    def model(x, amp, cen, width, skew):\n",
    "\n",
    "        return amp * np.exp(-((x - cen) / width)**2 / 2) * (1 + erf(skew * ((x - cen) / width) / np.sqrt(2)))\n",
    "\n",
    "    v = np.arange(-1000,1000,0.1)\n",
    "\n",
    "    peak = model(v, amp, cen, width, skew)    \n",
    "\n",
    "    loc = v[np.argmax(peak)]\n",
    "\n",
    "    half = np.amax(peak) / 2.0\n",
    "    signs = np.sign(np.add(peak, -half))\n",
    "    zero_crossings = (signs[0:-2] != signs[1:-1])\n",
    "    zero_crossings_i = np.where(zero_crossings)[0]\n",
    "\n",
    "    fwhm = abs(lin_interp(v, peak, zero_crossings_i[0], half) - lin_interp(v, peak, zero_crossings_i[1], half))\n",
    "\n",
    "    res = np.random.normal(R, R_error)\n",
    "\n",
    "    fwhm = np.sqrt((fwhm)**2 - (res)**2)\n",
    "\n",
    "    return fwhm, loc\n",
    "\n",
    "def label(fig, ax, fig_stack, ax_stack):\n",
    "\n",
    "    slits = np.array(['M5','M4','M6','M3','M0','M2','M7','M8','M9'], dtype=str)    \n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "\n",
    "        row[-1].yaxis.set_label_position('right')\n",
    "        row[-1].set_ylabel(slits[i], rotation=-90, labelpad=10)\n",
    "\n",
    "    ax_stack[0,6].yaxis.set_label_position('right')\n",
    "    ax_stack[0,6].set_ylabel('NL', rotation=-90, labelpad=10)\n",
    "\n",
    "    ax_stack[1,6].yaxis.set_label_position('right')\n",
    "    ax_stack[1,6].set_ylabel('L', rotation=-90, labelpad=10)\n",
    "\n",
    "    ax[3,0].set_title(r'$v_{\\rm{sep}}$')\n",
    "    ax[3,1].set_title('FWHM (blue)')\n",
    "    ax[0,2].set_title('FWHM (center)')\n",
    "    ax[0,3].set_title('FWHM (red)')\n",
    "    ax[0,4].set_title(r'$f_{\\rm{min}}/f_{\\rm{cont}}$')\n",
    "    ax[0,5].set_title('EW')\n",
    "    ax[0,6].set_title(r'$f_{\\rm{cen}}$')\n",
    "    ax[0,7].set_title('Luminosity')\n",
    "    \n",
    "    ax_stack[1,0].set_title(r'$v_{\\rm{sep}}$')\n",
    "    ax_stack[1,1].set_title('FWHM (blue)')\n",
    "    ax_stack[0,2].set_title('FWHM (center)')\n",
    "    ax_stack[0,3].set_title('FWHM (red)')\n",
    "    ax_stack[0,4].set_title(r'$f_{\\rm{min}}/f_{\\rm{cont}}$')\n",
    "    ax_stack[0,5].set_title('EW')\n",
    "    ax_stack[0,6].set_title(r'$f_{\\rm{cen}}$')\n",
    "\n",
    "    xlabels = np.array(['(km s$^{-1}$)','(km s$^{-1}$)','(km s$^{-1}$)',\n",
    "        '(km s$^{-1}$)','',r'($\\rm{\\AA}$)','(%)','(10$^{42}$ erg s$^{-1}$)'], dtype=str)\n",
    "\n",
    "    for i, column in enumerate(ax.T):\n",
    "\n",
    "        ax[8,i].set_xlabel(xlabels[i])\n",
    "\n",
    "    for i, column in enumerate(ax_stack.T):\n",
    "\n",
    "        ax_stack[1,i].set_xlabel(xlabels[i])\n",
    "\n",
    "    fig.supxlabel(r'$x-\\mu$')\n",
    "    fig.supylabel('Count')\n",
    "\n",
    "    fig_stack.supxlabel(r'$x-\\mu$')\n",
    "    fig_stack.supylabel('Count')\n",
    "\n",
    "def set_ticks(ax, ax_stack):\n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "\n",
    "        for j, column in enumerate(row):\n",
    "\n",
    "            if j == 7:\n",
    "                ax[i,j].tick_params(bottom=True, left=True, right=False)\n",
    "\n",
    "            else:\n",
    "                ax[i,j].tick_params(bottom=True, left=True, right=True)\n",
    "\n",
    "    ax[0,2].tick_params(labelleft=True)\n",
    "    ax[1,2].tick_params(labelleft=True)\n",
    "    ax[2,2].tick_params(labelleft=True)\n",
    "\n",
    "    for i, row in enumerate(ax_stack):\n",
    "\n",
    "        for j, column in enumerate(row):\n",
    "\n",
    "            if j == 6:\n",
    "                ax_stack[i,j].tick_params(bottom=True, left=True, right=False)\n",
    "\n",
    "            else:\n",
    "                ax_stack[i,j].tick_params(bottom=True, left=True, right=True)\n",
    "\n",
    "    ax_stack[0,2].tick_params(labelleft=True)\n",
    "\n",
    "def disable_plots(ax, ax_stack):\n",
    "\n",
    "    ax_stack[0,0].axis('off')    \n",
    "    ax_stack[0,1].axis('off')    \n",
    "\n",
    "    for i in [0,1,2]:\n",
    "\n",
    "        ax[i,0].axis('off')\n",
    "        ax[i,1].axis('off')\n",
    "\n",
    "def make_corner_plot():\n",
    "\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(8,8, figsize=(16,16), sharex='col', sharey='row', constrained_layout=True)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "\n",
    "        for j, subplot in enumerate(row):\n",
    "\n",
    "            subplot.set_aspect(1 / subplot.get_data_ratio(), adjustable='box')\n",
    "\n",
    "            if j > i:\n",
    "                ax[i,j].axis('off')\n",
    "    \n",
    "    #ax[0,0].set_aspect(1 / subplot.get_data_ratio(), adjustable='datalim')\n",
    "    #ax_dummy = fig.add_axes(ax[0,0].get_position())\n",
    "\n",
    "    #ax_dummy = ax[0,0].twinx()    \n",
    "    #ax_dummy.set_aspect('equal')\n",
    "\n",
    "    #row_titles = np.array(['FWHM(center)','FWHM (red)',r'$f_{\\rm{min}}/f_{\\rm{cont}}$','EW',r'$f_{\\rm{cen}}$','Luminosity',r'$f_{\\rm{esc}}^{\\rm{LyC}}$'], dtype=str)\n",
    "\n",
    "    row_titles = np.array(['FWHM (blue)', 'FWHM (center)', 'FWHM (red)', \n",
    "        r'$f_{\\rm{min}}/f_{\\rm{cont}}$', 'EW', r'$f_{\\rm{cen}}$',\n",
    "        'Luminosity', r'$f_{\\rm{esc}}^{\\rm{LyC}}$'], dtype=str)\n",
    "    column_titles = np.array([r'$v_{\\rm{sep}}$', 'FWHM (blue)', 'FWHM (center)',\n",
    "        'FWHM (red)', r'$f_{\\rm{min}}/f_{\\rm{cont}}$', 'EW', \n",
    "        r'$f_{\\rm{cen}}$', 'Luminosity'], dtype=str)\n",
    "    column_labels = np.array(['(km s$^{-1}$)', '(km s$^{-1}$)', '(km s$^{-1}$)',\n",
    "        '(km s$^{-1}$)', '', r'($\\rm{\\AA}$)',\n",
    "        '(%)', '(10$^{42}$ erg s$^{-1}$)'], dtype=str)\n",
    "    row_labels = np.array(['(km s$^{-1}$)', '(km s$^{-1}$)', '(km s$^{-1}$)',\n",
    "        '', r'($\\rm{\\AA}$)', '(%)', '(10$^{42}$ erg s$^{-1}$)', '(%)'], dtype=str)\n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "\n",
    "        ax[i,0].set_ylabel(row_titles[i], fontsize='large')\n",
    "        ax[i,i].set_title(column_titles[i])\n",
    "\n",
    "        ax[7,i].set_xlabel(column_labels[i], fontsize='large')\n",
    "\n",
    "        if i > 0:\n",
    "            ax[i,i].yaxis.set_label_position('right')\n",
    "            ax[i,i].set_ylabel(row_labels[i], fontsize='large')\n",
    "\n",
    "    for i, row in enumerate(ax):\n",
    "\n",
    "        for j, subplot in enumerate(row):\n",
    "\n",
    "            # Subplots on the interior\n",
    "            if ((i != j) & (i != 7) & (j != 0)):\n",
    "                subplot.tick_params(left=True, right=True, bottom=True, top=True,\n",
    "                    labelleft=False, labelright=False, labelbottom=False, labeltop=False, direction='in')\n",
    "\n",
    "            # Subplots on the main diagonal but not the corners\n",
    "            elif ((i == j) & (i != 7) & (j != 0)):\n",
    "                subplot.tick_params(left=True, right=True, bottom=True, top=True,\n",
    "                    labelleft=False, labelright=True, labelbottom=False, labeltop=False, direction='in')\n",
    "            \n",
    "            # Subplots on the left column but not the corners\n",
    "            elif ((j == 0) & (i != 0) & (i != 7)):\n",
    "                subplot.tick_params(left=True, right=True, bottom=True, top=True,\n",
    "                    labelleft=False, labelright=False, labelbottom=False, labeltop=False, direction='in')\n",
    "\n",
    "            # Subplots on the bottom row but not the corners\n",
    "            elif ((i == 7) & (j != 0) & (j != 7)):\n",
    "                subplot.tick_params(left=True, right=True, bottom=True, top=True,\n",
    "                    labelleft=False, labelright=False, labelbottom=True, labeltop=False, direction='in')\n",
    "\n",
    "    ax[0,0].tick_params(left=True, right=True, bottom=True, top=True,\n",
    "        labelleft=False, labelright=False, labelbottom=False, labeltop=False, direction='in')\n",
    "    ax[7,0].tick_params(left=True, right=True, bottom=True, top=True,\n",
    "        labelleft=False, labelright=False, labelbottom=True, labeltop=False, direction='in')\n",
    "    ax[7,7].tick_params(left=True, right=True, bottom=True, top=True,\n",
    "        labelleft=False, labelright=True, labelbottom=True, labeltop=False, direction='in')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "def gaussian(x, amp, cen, width):\n",
    "    return amp * np.exp(-((x - cen) / width)**2 / 2)\n",
    "\n",
    "def skewed_gaussian(x, amp, cen, width, skew):\n",
    "    return amp * np.exp(-((x - cen) / width)**2 / 2) * (1 + erf(skew * ((x - cen) / width) / np.sqrt(2)))\n",
    "\n",
    "def measure():\n",
    "\n",
    "    # Establish directories\n",
    "    home = os.getcwd()\n",
    "    data = home + '/data'\n",
    "    figs = home + '/figs'\n",
    "\n",
    "    #files = glob.glob(data + '/spectra/mage/*MWdr.txt')\n",
    "\n",
    "    files = np.array(['rest_sba-nonleaker-no_m3_MWdr.txt','rest_sba-leaker-no_m0_MWdr.txt',\n",
    "                      'psz-arcslit-h3-comb1_MWdr.txt', 'psz-arcslit-h1-comb1_MWdr.txt',\n",
    "                      'sunburst_M-6-comb1_MWdr.txt', 'psz-arcslit-h4-comb1_MWdr.txt',\n",
    "                      'planckarc_pos1-comb1_MWdr.txt', 'psz-arcslit-h6-comb1_MWdr.txt',\n",
    "                      'psz-arcslit-h9-comb1_MWdr.txt', 'psz-arcslit-f-comb1_MWdr.txt',\n",
    "                      'psz-arcslit-h2-comb1_MWdr.txt'], dtype=object)\n",
    "    names = np.array(['NL', 'L', 'M5', 'M4', 'M6', 'M3', 'M0', 'M2', 'M7', 'M8', 'M9'], dtype=str)\n",
    "\n",
    "    f_esc = [2.3, -0.6, 3, 2.3, 17, 18, 12, 15, 14]\n",
    "    ne_esc = [0.8, 0.2, 1, 0.8, 6, 7, 5, 6, 5]\n",
    "\n",
    "    # For each file\n",
    "    for i, file in enumerate(files):\n",
    "\n",
    "        # Join its folder path to the file name\n",
    "        file = ''.join([data, '/spectra/mage/', file])\n",
    "        files[i] = file\n",
    "\n",
    "    z = np.array([0, 0, 2.37086, 2.37073, 2.37021, 2.37025, 2.37014, 2.37017, 2.37044, \n",
    "                  2.37024, 2.37030], dtype=np.float64)\n",
    "    c_peak_range = np.array([[60,140],[20,130],[0,100],[0,85],[10,130],[35,120],[10,130],\n",
    "                             [45,125],[15,100],[25,125],[15,125]], dtype=np.float64)\n",
    "\n",
    "    fig_mc, ax_mc = plt.subplots(9,8, figsize=(16,18), sharey='row', constrained_layout=True)\n",
    "    fig_mc_stack, ax_mc_stack = plt.subplots(2,7, figsize=(21,6), sharey='row', constrained_layout=True)\n",
    "\n",
    "    fig_lya, ax_lya = plt.subplots(3,3, figsize=(12,12), sharex=True, constrained_layout=True)\n",
    "    ax_lya_array = np.array(ax_lya).reshape(-1)\n",
    "\n",
    "    fig_lya_stack, ax_lya_stack = plt.subplots(3,1, figsize=(3,9), sharex=True)#, constrained_layout=True)\n",
    "    #fig_lya_stack.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "    fig_c, ax_c = make_corner_plot()\n",
    "\n",
    "    total_result = np.array([np.empty((9,1000))])\n",
    "\n",
    "    mag = np.array([1.0, 1.0, 50.7, 14.6, 147.0, 36.1, 10.4, 31.6, 34.6, 29.4, 30.9], dtype=np.float64)\n",
    "\n",
    "    R = np.array([\n",
    "        299792.458 / 5400,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5500,\n",
    "        299792.458 / 5400,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5500,\n",
    "        299792.458 / 4700,\n",
    "        299792.458 / 5300,\n",
    "        299792.458 / 5200,\n",
    "        299792.458 / 5200,\n",
    "        299792.458 / 5500\n",
    "    ])\n",
    "\n",
    "    R_error = np.array([\n",
    "        299792.458 / 5400**2 * 200,\n",
    "        299792.458 / 5300**2 * 200,\n",
    "        299792.458 / 5500**2 * 400,\n",
    "        299792.458 / 5400**2 * 300,\n",
    "        299792.458 / 5300**2 * 300,\n",
    "        299792.458 / 5500**2 * 400,\n",
    "        299792.458 / 4700**2 * 200,\n",
    "        299792.458 / 5300**2 * 300,\n",
    "        299792.458 / 5200**2 * 200,\n",
    "        299792.458 / 5200**2 * 300,\n",
    "        299792.458 / 5500**2 * 400\n",
    "    ])\n",
    "\n",
    "    # For each spectrum\n",
    "    for i, file in enumerate(files):\n",
    "\n",
    "        print(names[i])\n",
    "\n",
    "        # Extract the data from the .txt file\n",
    "        w, f, n = extract_data(file)\n",
    "\n",
    "        # Place the data in the rest frame\n",
    "        w, f, n = rest_frame(w, f, n, z[i])\n",
    "\n",
    "        f = f[(w >= 1195) & (w <= 1235)]\n",
    "        n = n[(w >= 1195) & (w <= 1235)]\n",
    "        w = w[(w >= 1195) & (w <= 1235)]\n",
    "\n",
    "        v = 299792.458 * (w / 1215.67 - 1)\n",
    "\n",
    "        #cosmology = FlatLambdaCDM(70, 0.3)\n",
    "        #l_distance = cosmology.luminosity_distance(z[i]).value * 3.086e24\n",
    "\n",
    "        fit_results, e_results, fcen_results, ratio_results, l_results = mc(w, v, f, n, z[i], c_peak_range[i], i)    \n",
    "\n",
    "        median_fit = [np.median(e) for e in fit_results.T]\n",
    "\n",
    "        # Take the transpose of the results so that the rows\n",
    "        # are by parameter, not sample number\n",
    "        #fit_results = fit_results.T\n",
    "\n",
    "        if i in [0,2,3,4]:\n",
    "            stdv_c_results = fit_results.T[6]\n",
    "            fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * stdv_c_results\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_c_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_r, _ = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "                fwhm_c, _ = compute_fwhm_and_peak(sample[4], sample[5], sample[6], 0, R[i], R_error[i])\n",
    "                fwhm_c_results = np.append(fwhm_c_results, fwhm_c)\n",
    "\n",
    "                if np.isnan(fwhm_c):\n",
    "                    print(i, fwhm_c)\n",
    "\n",
    "        else:\n",
    "            stdv_c_results = fit_results.T[10]\n",
    "            fwhm_c_results = 2 * np.sqrt(2 * np.log(2)) * stdv_c_results\n",
    "\n",
    "            fwhm_b_results = np.array([], dtype=np.float64)\n",
    "            fwhm_c_results = np.array([], dtype=np.float64)\n",
    "            fwhm_r_results = np.array([], dtype=np.float64)\n",
    "            vsep_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            for j, sample in enumerate(fit_results):\n",
    "\n",
    "                fwhm_b, loc_b = compute_fwhm_and_peak(sample[0], sample[1], sample[2], sample[3], R[i], R_error[i])\n",
    "                fwhm_b_results = np.append(fwhm_b_results, fwhm_b)\n",
    "\n",
    "                fwhm_c, _ = compute_fwhm_and_peak(sample[8], sample[9], sample[10], 0, R[i], R_error[i])\n",
    "                fwhm_c_results = np.append(fwhm_c_results, fwhm_c)\n",
    "\n",
    "                if np.isnan(fwhm_c):\n",
    "                    print(i, fwhm_c)\n",
    "\n",
    "                fwhm_r, loc_r = compute_fwhm_and_peak(sample[4], sample[5], sample[6], sample[7], R[i], R_error[i])\n",
    "                fwhm_r_results = np.append(fwhm_r_results, fwhm_r)\n",
    "\n",
    "                vsep = abs(loc_r - loc_b)\n",
    "                vsep_results = np.append(vsep_results, vsep)\n",
    "\n",
    "        fwhm_c_results = fwhm_c_results[~np.isnan(fwhm_c_results)]\n",
    "\n",
    "        # If the spectrum is one of the stacked spectra\n",
    "        if i < 2:\n",
    "\n",
    "            if i == 0:\n",
    "                color='#DC3220'\n",
    "                markersize = 8\n",
    "            else:\n",
    "                color='#005AB5'\n",
    "                markersize = 8\n",
    "\n",
    "            ax_mc_stack[i,0].hist(vsep_results - np.median(vsep_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,1].hist(fwhm_b_results - np.median(fwhm_b_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,2].hist(fwhm_c_results - np.median(fwhm_c_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,3].hist(fwhm_r_results - np.median(fwhm_r_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,4].hist(ratio_results - np.median(ratio_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,5].hist(e_results - np.median(e_results), bins=30, color=color)\n",
    "            ax_mc_stack[i,6].hist(fcen_results - np.median(fcen_results), bins=30, color=color)\n",
    "\n",
    "            results = [vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results]\n",
    "            r = np.array([None,None,None,None,1,1,1])\n",
    "            tau = np.array([None,None,None,None,1,1,1])\n",
    "            rho = np.array([None,None,None,None,1,1,1])\n",
    "\n",
    "            # For each subplot in a row\n",
    "            for j, subplot in enumerate(ax_mc_stack[i]):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    median = np.median(results[j][~np.isnan(results[j])])\n",
    "                    lower = sigfig.round(str(median - np.percentile(results[j][~np.isnan(results[j])], 16)), 2)\n",
    "                    upper = sigfig.round(str(np.percentile(results[j][~np.isnan(results[j])], 84) - median), 2)\n",
    "\n",
    "                    # If both percentiles are greater than 10, they will not have\n",
    "                    # any significant figures past the decimal place\n",
    "                    if abs(float(lower)) >= 10 and abs(float(upper)) >= 10:\n",
    "                        # Find the smallest value between the two percentiles\n",
    "                        string = str(np.amin([int(lower), int(upper)]))\n",
    "\n",
    "                        # Count the number of zeros in the string\n",
    "                        zeros = string.count('0')\n",
    "\n",
    "                        # If the length of the string differs by only one from\n",
    "                        # the number of zeros, this indicates one of the 2 \n",
    "                        # significant figures is a zero, so to prevent the median\n",
    "                        # from being rounded prematurely (to the significant figure\n",
    "                        # before the zero), subtract the number of zeros by one\n",
    "                        if len(string) == zeros + 1:\n",
    "                            zeros = zeros - 1\n",
    "\n",
    "                        zeros = -1 * zeros\n",
    "\n",
    "                        median = str(int(round(median, zeros)))\n",
    "\n",
    "                    elif (abs(float(lower)) >= 10 and abs(float(upper)) < 10) or (abs(float(lower)) < 10 and abs(float(upper)) >= 10):\n",
    "                        print('check')\n",
    "\n",
    "                        if abs(float(lower)) >= 10:\n",
    "                            median = str(round(median, len(upper.split('.')[1])))\n",
    "                        if abs(float(upper)) >= 10:\n",
    "                            median = str(round(median, len(lower.split('.')[1])))\n",
    "                        # Round the median to the smallest digit place between the upper and lower percentiles   \n",
    "                        #median = str(round(median, np.amax([len(lower.split('.')[1]), len(upper.split('.')[1])])))\n",
    "\n",
    "                    # Otherwise, since the percentiles are rounded to 2 significant\n",
    "                    # figures, they will have at least one significant digit past\n",
    "                    # the decimal place\n",
    "                    else:\n",
    "                        # Round the median to the smallest digit place between the upper and lower percentiles   \n",
    "                        median = str(round(median, np.amax([len(lower.split('.')[1]), len(upper.split('.')[1])])))\n",
    "\n",
    "                    at = AnchoredText('$' + median + '_{-' + lower + '}^{+' + upper + '}$',\n",
    "                        loc='upper right', frameon=False)\n",
    "                    subplot.add_artist(at)\n",
    "\n",
    "                # Except if there are no results for the parameter\n",
    "                # (because it was inapplicable to the profile)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "            ax_lya_stack[0].fill_between(v[(v >= -1100) & (v <= 1100)], (f - 3 * n)[(v >= -1100) & (v <= 1100)], (f + 3 * n)[(v >= -1100) & (v <= 1100)], step='mid', facecolor=color, alpha=0.3)\n",
    "            ax_lya_stack[0].plot(v[(v >= -1100) & (v <= 1100)], f[(v >= -1100) & (v <= 1100)], ds='steps-mid', c=color)\n",
    "\n",
    "            for j, result_row in enumerate([fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results]):\n",
    "                \n",
    "                # If this is the stacked nonleaker spectrum\n",
    "                if i == 0:\n",
    "                    if j == 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        for k, result_col in enumerate([fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results]):\n",
    "                            \n",
    "                            if k + 2 > j:\n",
    "                                pass\n",
    "                            else:\n",
    "                                ax_c[j,k+2].errorbar(np.median(result_col), np.median(result_row), \n",
    "                                    xerr=[[np.median(result_col) - np.percentile(result_col, 16)], [np.percentile(result_col, 84) - np.median(result_col)]], \n",
    "                                    yerr=[[np.median(result_row) - np.percentile(result_row, 16)], [np.percentile(result_row, 84) - np.median(result_row)]],\n",
    "                                    lw=1, marker='s', markersize=markersize, mec=color, mfc=color, ecolor=color)\n",
    "                else:\n",
    "                    for k, col in enumerate([vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results]):\n",
    "\n",
    "                        if k > j:\n",
    "                            pass\n",
    "                        else:\n",
    "                            ax_c[j,k].errorbar(np.median(col), np.median(result_row),\n",
    "                                xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                yerr=[[np.median(result_row) - np.percentile(result_row, 16)], [np.percentile(result_row, 84) - np.median(result_row)]],\n",
    "                                lw=1, marker='o', markersize=markersize, mec=color, mfc=color, ecolor=color)\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                ax_lya_stack[1].fill_between(v[(v >= -1100) & (v <= 1100)], (f - 3 * n)[(v >= -1100) & (v <= 1100)], (f + 3 * n)[(v >= -1100) & (v <= 1100)], step='mid', facecolor=color, alpha=0.3)\n",
    "                ax_lya_stack[1].plot(v[(v >= -1100) & (v <= 1100)], f[(v >= -1100) & (v <= 1100)], ds='steps-mid', c=color)\n",
    "                ax_lya_stack[1].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[4], median_fit[5], median_fit[6]) + median_fit[7])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_stack[1].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[0], median_fit[1], median_fit[2], median_fit[3]) + median_fit[7])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_stack[1].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[4], median_fit[5], median_fit[6]) + skewed_gaussian(v, median_fit[0], median_fit[1], median_fit[2], median_fit[3]) + median_fit[7])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dashed')\n",
    "\n",
    "            else:\n",
    "\n",
    "                ax_lya_stack[2].fill_between(v[(v >= -1100) & (v <= 1100)], (f - 3 * n)[(v >= -1100) & (v <= 1100)], (f + 3 * n)[(v >= -1100) & (v <= 1100)], step='mid', facecolor=color, alpha=0.3)\n",
    "                ax_lya_stack[2].plot(v[(v >= -1100) & (v <= 1100)], f[(v >= -1100) & (v <= 1100)], ds='steps-mid', c=color)\n",
    "                ax_lya_stack[2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[8], median_fit[9], median_fit[10]) + median_fit[11])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_stack[2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[0], median_fit[1], median_fit[2], median_fit[3]) + median_fit[11])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_stack[2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[4], median_fit[5], median_fit[6], median_fit[7]) + median_fit[11])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_stack[2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[8], median_fit[9], median_fit[10]) + skewed_gaussian(v, median_fit[4], median_fit[5], median_fit[6], median_fit[7]) + skewed_gaussian(v, median_fit[0], median_fit[1], median_fit[2], median_fit[3]) + median_fit[11])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dashed')\n",
    "\n",
    "        # If the spectrum is not one of the stacked spectra\n",
    "        elif i > 1:\n",
    "\n",
    "            if i in [2,3,4]:\n",
    "                color='#DC3220'\n",
    "                marker = 's'\n",
    "                markersize = 8\n",
    "\n",
    "            elif i == 5:\n",
    "                color='#D35FB7'\n",
    "                marker = '*'\n",
    "                markersize = 10\n",
    "\n",
    "            else:\n",
    "                color='#005AB5'\n",
    "                marker = 'o'\n",
    "                markersize = 8\n",
    "\n",
    "            ax_mc[i-2,0].hist(vsep_results - np.median(vsep_results), bins=30, color=color)\n",
    "            ax_mc[i-2,1].hist(fwhm_b_results - np.median(fwhm_b_results), bins=30, color=color)\n",
    "            ax_mc[i-2,2].hist(fwhm_c_results - np.median(fwhm_c_results), bins=30, color=color)\n",
    "            ax_mc[i-2,3].hist(fwhm_r_results - np.median(fwhm_r_results), bins=30, color=color)\n",
    "            ax_mc[i-2,4].hist(ratio_results - np.median(ratio_results), bins=30, color=color)\n",
    "            ax_mc[i-2,5].hist(e_results - np.median(e_results), bins=30, color=color)\n",
    "            ax_mc[i-2,6].hist(fcen_results - np.median(fcen_results), bins=30, color=color)\n",
    "            ax_mc[i-2,7].hist((l_results - np.median(l_results)) * 1e-42, bins=30, color=color)\n",
    "            \n",
    "            results = [vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42]\n",
    "            r = np.array([None,None,None,None,1,1,1,1])\n",
    "            tau = np.array([None,None,None,None,1,1,1,1])\n",
    "            rho = np.array([None,None,None,None,1,1,1,1])\n",
    "\n",
    "            # For each subplot in a row\n",
    "            for j, subplot in enumerate(ax_mc[i-2]):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    #median = np.median(results[j])\n",
    "                    #lower = median - np.percentile(results[j], 16)\n",
    "                    #upper = np.percentile(results[j], 84) - median\n",
    "\n",
    "                    median = np.median(results[j][~np.isnan(results[j])])\n",
    "                    lower = sigfig.round(str(median - np.percentile(results[j][~np.isnan(results[j])], 16)), 2)\n",
    "                    upper = sigfig.round(str(np.percentile(results[j][~np.isnan(results[j])], 84) - median), 2)\n",
    "\n",
    "                    #print(median, lower, upper)\n",
    "\n",
    "                    # If both percentiles are greater than 10, they will not have\n",
    "                    # any significant figures past the decimal place\n",
    "                    if abs(float(lower)) >= 10 and abs(float(upper)) >= 10:\n",
    "                        # Find the smallest value between the two percentiles\n",
    "                        string = str(np.amin([int(lower), int(upper)]))\n",
    "\n",
    "                        # Count the number of zeros in the string\n",
    "                        zeros = string.count('0')\n",
    "\n",
    "                        # If the length of the string differs by only one from\n",
    "                        # the number of zeros, this indicates one of the 2 \n",
    "                        # significant figures is a zero, so to prevent the median\n",
    "                        # from being rounded prematurely (to the significant figure\n",
    "                        # before the zero), subtract the number of zeros by one\n",
    "                        if len(string) == zeros + 1:\n",
    "                            zeros = zeros - 1\n",
    "\n",
    "                        zeros = -1 * zeros\n",
    "\n",
    "                        median = str(int(round(median, zeros)))\n",
    "                    \n",
    "                    elif (abs(float(lower)) >= 10 and abs(float(upper)) < 10) or (abs(float(lower)) < 10 and abs(float(upper)) >= 10):\n",
    "                        print('check')\n",
    "                        \n",
    "                        if abs(float(lower)) >= 10:\n",
    "                            formatter = '{:.' + str(len(upper.split('.')[1])) + 'f}'\n",
    "                            median = formatter.format(round(median, len(upper.split('.')[1])))\n",
    "                        if abs(float(upper)) >= 10:\n",
    "                            formatter = '{:.' + str(len(lower.split('.')[1])) + 'f}'\n",
    "                            median = formatter.format(round(median, len(lower.split('.')[1])))\n",
    "                        # Round the median to the smallest digit place between the upper and lower percentiles   \n",
    "                        #median = str(round(median, np.amax([len(lower.split('.')[1]), len(upper.split('.')[1])])))\n",
    "\n",
    "                    # Otherwise, since the percentiles are rounded to 2 significant\n",
    "                    # figures, they will have at least one significant digit past\n",
    "                    # the decimal place\n",
    "                    else:\n",
    "                        # Round the median to the smallest digit place between the upper and lower percentiles   \n",
    "                        formatter = '{:.' + str(np.amax([len(lower.split('.')[1]), len(upper.split('.')[1])])) + 'f}'\n",
    "                        median = formatter.format(round(median, np.amax([len(lower.split('.')[1]), len(upper.split('.')[1])])))\n",
    "\n",
    "                    #at = AnchoredText('$' + str(round(median, r[j])) + '_{-' + str(round(lower, r[j])) + '}^{+' + str(round(upper, r[j])) + '}$',\n",
    "                    #    loc='upper right', frameon=False)\n",
    "                    at = AnchoredText('$' + median + '_{-' + lower + '}^{+' + upper + '}$',\n",
    "                        loc='upper right', frameon=False)\n",
    "                    subplot.add_artist(at)\n",
    "\n",
    "                # Except if there are no results for the parameter\n",
    "                # (because it was inapplicable to the profile)\n",
    "                except IndexError:\n",
    "                    pass\n",
    "\n",
    "            ax_lya_array[i-2].fill_between(v[(v >= -1100) & (v <= 1100)], (f / mag[i] - 2 * n / mag[i])[(v >= -1100) & (v <= 1100)] * 1e17, (f / mag[i] + 2 * n / mag[i])[(v >= -1100) & (v <= 1100)] * 1e17, step='mid', facecolor=color, alpha=0.3)\n",
    "            ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)], (f / mag[i])[(v >= -1100) & (v <= 1100)] * 1e17, ds='steps-mid', c=color)\n",
    "\n",
    "            if i in [2,3,4]:\n",
    "\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[4] / mag[i], median_fit[5], median_fit[6]) + median_fit[7] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[0] / mag[i], median_fit[1], median_fit[2], median_fit[3]) + median_fit[7] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[4] / mag[i], median_fit[5], median_fit[6]) + skewed_gaussian(v, median_fit[0] / mag[i], median_fit[1], median_fit[2], median_fit[3]) + median_fit[7] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dashed')\n",
    "\n",
    "            else:\n",
    "\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[8] / mag[i], median_fit[9], median_fit[10]) + median_fit[11] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[0] / mag[i], median_fit[1], median_fit[2], median_fit[3]) + median_fit[11] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (skewed_gaussian(v, median_fit[4] / mag[i], median_fit[5], median_fit[6], median_fit[7]) + median_fit[11] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dotted')\n",
    "                ax_lya_array[i-2].plot(v[(v >= -1100) & (v <= 1100)],\n",
    "                    (gaussian(v, median_fit[8] / mag[i], median_fit[9], median_fit[10]) + skewed_gaussian(v, median_fit[4] / mag[i], median_fit[5], median_fit[6], median_fit[7]) + skewed_gaussian(v, median_fit[0] / mag[i], median_fit[1], median_fit[2], median_fit[3]) + median_fit[11] / mag[i])[(v >= -1100) & (v <= 1100)],\n",
    "                    color='black', ls='dashed')\n",
    "\n",
    "            at = AnchoredText(names[i], loc='upper right', frameon=False, prop=dict(fontsize='large'))\n",
    "            ax_lya_array[i-2].add_artist(at)\n",
    "\n",
    "            ax_lya_array[i-2].set_xlim(-1000,1000)\n",
    "            ax_lya_array[i-2].set_ylim(bottom=0)\n",
    "\n",
    "            # For each parameter row\n",
    "            for j, row in enumerate([fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42, f_esc[i-2]]):\n",
    "                \n",
    "                # If the spectrum does not have a triple peak\n",
    "                if i in [2,3,4]:\n",
    "                    \n",
    "                    # For each parameter column\n",
    "                    for k, col in enumerate([fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42]):\n",
    "                        if k + 2 > j:\n",
    "                            pass\n",
    "                        else:\n",
    "                            if j == 0:\n",
    "                                pass\n",
    "                            elif j == 7:\n",
    "                                ax_c[j,k+2].errorbar(np.median(col), f_esc[i-2],\n",
    "                                    xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                    yerr=ne_esc[i-2],\n",
    "                                    lw=1, marker=marker, markersize=markersize, mec=color, mfc='none', ecolor=color)\n",
    "                            else:\n",
    "                                ax_c[j,k+2].errorbar(np.median(col), np.median(row),\n",
    "                                    xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                    yerr=[[np.median(row) - np.percentile(row, 16)], [np.percentile(row, 84) - np.median(row)]],\n",
    "                                    lw=1, marker=marker, markersize=markersize, mec=color, mfc='none', ecolor=color)\n",
    "                else:\n",
    "                    for k, col in enumerate([vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42]):\n",
    "                        \n",
    "                        # If the row / column combination is above the main diagonal\n",
    "                        if k > j:\n",
    "                            pass\n",
    "\n",
    "                        else:\n",
    "                            if (j == 7) and (i != 6):\n",
    "                                ax_c[j,k].errorbar(np.median(col), f_esc[i-2],\n",
    "                                    xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                    yerr=ne_esc[i-2],\n",
    "                                    lw=1, marker=marker, markersize=markersize, mec=color, mfc='none', ecolor=color)\n",
    "                            elif (j == 7) and (k != 7) and (i == 6):\n",
    "                                ax_c[j,k].errorbar(np.median(col), f_esc[i-2],\n",
    "                                    xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                    yerr=ne_esc[i-2],\n",
    "                                    lw=1, marker=marker, markersize=markersize, mec=color, mfc='none', ecolor=color)\n",
    "                            elif (j == 6 or k == 7) and (i == 6):\n",
    "                                pass\n",
    "                            else:\n",
    "                                ax_c[j,k].errorbar(np.median(col), np.median(row),\n",
    "                                    xerr=[[np.median(col) - np.percentile(col, 16)], [np.percentile(col, 84) - np.median(col)]], \n",
    "                                    yerr=[[np.median(row) - np.percentile(row, 16)], [np.percentile(row, 84) - np.median(row)]],\n",
    "                                    lw=1, marker=marker, markersize=markersize, mec=color, mfc='none', ecolor=color)\n",
    "\n",
    "        # If the spectrum is not a stacked one\n",
    "        if i > 1:\n",
    "            # Create pseudo-measurements of the LyC escape fraction assuming the calculated value and standard deviation\n",
    "            # correspond to a Gaussian mean and standard deviation\n",
    "            fesc_results = np.random.normal(f_esc[i-2], ne_esc[i-2], 1000)\n",
    "\n",
    "        else:\n",
    "            fesc_results = np.empty(1000)\n",
    "            fesc_results[:] = np.nan\n",
    "\n",
    "        slit_result = np.array([np.empty(1000)])\n",
    "\n",
    "        for j, result in enumerate([vsep_results, fwhm_b_results, fwhm_c_results, fwhm_r_results, ratio_results, e_results, fcen_results, l_results * 1e-42, fesc_results]):\n",
    "            \n",
    "            # Try to append any missing values as NaNs\n",
    "            try:\n",
    "                if len(result) < 1000:\n",
    "                    a = np.empty(1000 - len(result))\n",
    "                    a[:] = np.nan\n",
    "\n",
    "                    result = np.append(result, a)\n",
    "\n",
    "            # Unless the array has not been instantiated\n",
    "            except TypeError:\n",
    "                result = np.empty(1000)\n",
    "                result[:] = np.nan\n",
    "            \n",
    "            if (i == 6) and (j == 7):\n",
    "                result = np.empty(1000)\n",
    "                result[:] = np.nan\n",
    "\n",
    "            result = np.where(result != 0.0, result, np.nan)\n",
    "\n",
    "            slit_result = np.append(slit_result, np.array([result]), axis=0)\n",
    "\n",
    "        # Drop the first row since it is empty\n",
    "        slit_result = slit_result[1:]\n",
    "\n",
    "        total_result = np.append(total_result, np.array([slit_result]), axis=0)\n",
    "\n",
    "    total_result = total_result[1:]\n",
    "\n",
    "    r_locs = [[3,0,0,0,0,0,0,0],\n",
    "        [2,4,0,0,0,0,0,0],\n",
    "        [1,1,2,0,0,0,0,0],\n",
    "        [3,3,2,7,0,0,0,0],\n",
    "        [3,3,2,7,2,0,0,0],\n",
    "        [3,3,2,7,2,2,1,1],\n",
    "        [3,3,2,1,2,2,2,1],\n",
    "        [2,'center left',2,4,2,2,2,2]]\n",
    "\n",
    "    # For each row in the corner plot\n",
    "    for i, row in enumerate(ax_c):\n",
    "\n",
    "        # For each column in the corner plot\n",
    "        for j, subplot in enumerate(row):\n",
    "\n",
    "            r_results = np.array([], dtype=np.float64)\n",
    "            tau_results = np.array([], dtype=np.float64)\n",
    "            rho_results = np.array([], dtype=np.float64)\n",
    "\n",
    "            # If the row / column pair is above the main diagonal\n",
    "            if j > i:\n",
    "                pass\n",
    "            else:\n",
    "\n",
    "                x_data = np.empty(1000)\n",
    "                x_data[:] = np.nan\n",
    "                x_data = np.array([x_data])\n",
    "                y_data = np.empty(1000)\n",
    "                y_data[:] = np.nan\n",
    "                y_data = np.array([y_data])\n",
    "\n",
    "                # For each spectrum\n",
    "                for k, slit in enumerate(total_result):\n",
    "                    \n",
    "                    if all(np.isnan(slit[j])) or all(np.isnan(slit[i + 1])):\n",
    "                        pass\n",
    "                    else:\n",
    "                        #if ~all(np.isnan(slit[j])) and ~all(np.isnan(slit[j + 1])):\n",
    "                        x_data = np.append(x_data, np.array([slit[j]]), axis=0)\n",
    "                        y_data = np.append(y_data, np.array([slit[i + 1]]), axis=0)\n",
    "                        #pass\n",
    "                    '''\n",
    "                    else:\n",
    "                        x_data = np.append(x_data, np.array([slit[j]]), axis=0)\n",
    "                        y_data = np.append(x_data, np.array([slit[j + 1]]), axis=0)\n",
    "                    '''\n",
    "\n",
    "                x_data = x_data[1:]\n",
    "                y_data = y_data[1:]\n",
    "\n",
    "                #r_results = np.array([], dtype=np.float64)\n",
    "                #tau_results = np.array([], dtype=np.float64)\n",
    "                #rho_results = np.array([], dtype=np.float64)\n",
    "\n",
    "                if (i==6) and (j==6):\n",
    "                    pass\n",
    "                    #print(x_data)\n",
    "                    #print(y_data)\n",
    "\n",
    "                for k, sample in enumerate(x_data[0]):\n",
    "\n",
    "                    x = x_data[:,k]\n",
    "                    y = y_data[:,k]\n",
    "\n",
    "                    if any(np.isnan(x)) or any(np.isnan(y)):\n",
    "                        pass\n",
    "                    else:\n",
    "                        x = x[x != 0]\n",
    "                        y = y[y != 0]\n",
    "\n",
    "                        r = np.corrcoef(x, y)[0,1]\n",
    "                        tau = kendalltau(x, y).statistic\n",
    "                        rho = spearmanr(x, y).statistic\n",
    "\n",
    "                        r_results = np.append(r_results, r)\n",
    "                        tau_results = np.append(tau_results, tau)\n",
    "                        rho_results = np.append(rho_results, rho)\n",
    "\n",
    "                print(i, j)\n",
    "                print(len(r_results), np.median(r_results), \n",
    "                    sf_round(abs(np.median(r_results) - np.percentile(r_results, 16)),1), \n",
    "                    sf_round(abs(np.percentile(r_results, 84) - np.median(r_results)),1))\n",
    "                print(len(tau_results), np.median(tau_results), \n",
    "                    sf_round(abs(np.median(tau_results) - np.percentile(tau_results, 16)),1), \n",
    "                    sf_round(abs(np.percentile(tau_results, 84) - np.median(tau_results)),1))\n",
    "                print(len(rho_results), np.median(rho_results), \n",
    "                    sf_round(abs(np.median(rho_results) - np.percentile(rho_results, 16)),1), \n",
    "                    sf_round(abs(np.percentile(rho_results, 84) - np.median(rho_results)),1))\n",
    "                \n",
    "                '''\n",
    "                for k in [r_results, tau_results]:\n",
    "\n",
    "                    median = np.median(k)\n",
    "                    p16 = abs(np.median(k) - np.percentile(k, 16))\n",
    "                    p84 = abs(np.percentile(k, 84) - np.median(k))\n",
    "\n",
    "                    print(median, p16, p84)\n",
    "\n",
    "                    print(len(k), np.median(k), abs(np.median(r_results) - np.percentile(r_results, 16)), abs(np.percentile(r_results, 84) - np.median(r_results)))   \n",
    "\n",
    "                    plt.hist(k, bins=20)\n",
    "                    plt.show()\n",
    "                '''\n",
    "\n",
    "                lower = sigfig.round(abs(np.median(r_results) - np.percentile(r_results, 16)), 2)\n",
    "                upper = sigfig.round(abs(np.percentile(r_results, 84) - np.median(r_results)), 2)\n",
    "\n",
    "                d = [decimal.Decimal(lower).as_tuple().exponent, decimal.Decimal(upper).as_tuple().exponent]\n",
    "                d = abs(np.argmax(d))\n",
    "\n",
    "                at = AnchoredText('$' + '{:.2f}'.format(round(np.median(r_results), 2)) + '_{-' + '{:.2f}'.format(round(np.median(r_results) - np.percentile(r_results, 16), 2)) + '}^{+' + '{:.2f}'.format(round(np.percentile(r_results, 84) - np.median(r_results), 2))  + '}$',\n",
    "                    loc=r_locs[i][j], frameon=False, prop=dict(fontsize='small'))\n",
    "                ax_c[i,j].add_artist(at)\n",
    "\n",
    "    #ax_lya[2,1].set_xlabel('Velocity (km s$^{-1}$)', fontsize='large')\n",
    "    #ax_lya[1,0].set_ylabel(r'Flux density (10$^{-16}$ erg s$^{-1}$ cm$^{-2}$ $\\rm{\\AA}^{-1}$)', fontsize='large')\n",
    "\n",
    "    #for ax in [ax_top, ax_left, ax_right]:\n",
    "    #    ax.set_xlim(-1000,1000)\n",
    "    #    ax.set_ylim(bottom=0)\n",
    "\n",
    "    for i, ax in enumerate(ax_lya_stack):\n",
    "        ax.set_xlim(-1000,1000)\n",
    "        ax.set_ylim(bottom=0)\n",
    "\n",
    "        ax.tick_params(top=True, bottom=True, left=True, right=True, labelleft=True)\n",
    "\n",
    "    ax_lya_stack[2].set_xlabel('Velocity (km s$^{-1}$)')\n",
    "    ax_lya_stack[1].set_ylabel('Flux density (arb. scale)')\n",
    "\n",
    "    #ax_left.tick_params(left=False, labelleft=False)\n",
    "    #ax_right.tick_params(left=False, labelleft=False)\n",
    "\n",
    "    for i, ax_list in enumerate(ax_mc):\n",
    "\n",
    "        for j, subplot in enumerate(ax_list):\n",
    "\n",
    "            subplot.set_aspect(1 / subplot.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    for i, ax_list in enumerate(ax_mc_stack):\n",
    "\n",
    "        for j, subplot in enumerate(ax_list):\n",
    "\n",
    "            subplot.set_aspect(1 / subplot.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    '''\n",
    "    for i in ['top', 'left', 'right']:\n",
    "\n",
    "        ax_lya_stack[i].set_aspect(1 / ax_lya_stack[i].get_data_ratio(), adjustable='box')\n",
    "    '''\n",
    "\n",
    "    for i, ax in enumerate(ax_lya_stack):\n",
    "\n",
    "        #ax.set_aspect(1 / ax.get_data_ratio(), adjustable='box')\n",
    "        ax.tick_params(direction='in')\n",
    "\n",
    "    ax_lya_stack[1].set_yticks([0,3,6,9,12])\n",
    "\n",
    "    #for ax in [ax_top, ax_left, ax_right]:\n",
    "\n",
    "    #    ax.set_aspect(1 / ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    for i, ax in enumerate(ax_lya_array):\n",
    "\n",
    "        ax.set_aspect(1 / ax.get_data_ratio(), adjustable='box')\n",
    "        ax.tick_params(top=True, bottom=True, left=True, right=True, labelleft=True, direction='in')\n",
    "\n",
    "    for i in [0,1,2]:\n",
    "        \n",
    "        ax_lya[2,i].set_xticks([-1000,-500,0,500,1000])\n",
    "    \n",
    "    ax_lya[2,1].set_xlabel('Velocity (km s$^{-1}$)', fontsize='large')\n",
    "    ax_lya[1,0].set_ylabel(r'Flux density (10$^{-17}$ erg s$^{-1}$ cm$^{-2}$ $\\rm{\\AA}^{-1}$)', fontsize='large')\n",
    "\n",
    "    #fig_lya_stack.tight_layout()\n",
    "\n",
    "    fig_lya.savefig(figs + '/lya_fits.pdf', bbox_inches='tight')\n",
    "\n",
    "    label(fig_mc, ax_mc, fig_mc_stack, ax_mc_stack)\n",
    "    set_ticks(ax_mc, ax_mc_stack)\n",
    "    disable_plots(ax_mc, ax_mc_stack)\n",
    "\n",
    "    for i, row in enumerate(ax_c):\n",
    "\n",
    "        for j, subplot in enumerate(row):\n",
    "            \n",
    "            if j > i:\n",
    "                subplot.axis('off')\n",
    "            else:\n",
    "                subplot.set_aspect(1 / subplot.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    fig_lya_stack.subplots_adjust(hspace=0, wspace=0)\n",
    "\n",
    "    fig_lya_stack.savefig(figs + '/lya_fits_stack.pdf', bbox_inches='tight')\n",
    "\n",
    "    f = lambda x: x\n",
    "    g = lambda x: x\n",
    "\n",
    "    ax_2 = ax_c[0,0].secondary_yaxis('right', functions=(f,g))\n",
    "    ax_2.set_ylabel('(km s$^{-1}$)', fontsize='large')\n",
    "\n",
    "    fig_c.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "\n",
    "    fig_c.savefig(figs + '/corner.pdf', bbox_inches='tight')\n",
    "\n",
    "    fig_mc.savefig(figs + '/mc.pdf', bbox_inches='tight')\n",
    "    fig_mc_stack.savefig(figs + '/mc_stack.pdf', bbox_inches='tight')\n",
    "\n",
    "    #make_corner_plot()\n",
    "    \n",
    "    #plt.subplots_adjust(wspace=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edea5d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16844/2806096226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmeasure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16844/1970065138.py\u001b[0m in \u001b[0;36mmeasure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{results}/lya_fits/{slit_id}/{slit_id}_best_fit_parameters.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mmedian_fit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfit_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# Take the transpose of the results so that the rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fit_results' is not defined"
     ]
    }
   ],
   "source": [
    "measure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b2b404ef7cfffcb2d9e58206576e0220bed399f08fa92bc6fd125b02b641f3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
